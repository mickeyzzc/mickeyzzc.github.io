<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>About me</title><url>/about.html</url><categories/><tags/><content type="html"> 技术标签： Python 用flask框架写过一些服务。
Lua 用Openresty的时候写过一些简易webapi，在hekad中也简单使用过。
Java 在达内培训过，略懂基本
Bash 工作需要常写，有写复杂脚本的能力，请点击 MLSBS ,相关的 GIT库 VBA 看不惯EXCEL的时候写了一些批处理函数
工具篇（近期在用）： Ansible 虚拟化工具（Docker，Openvz） Tumx + Git + OhMyZsh + VIM</content></entry><entry><title>ANSIBLE管理线上docker集群</title><url>/posts/old/ansible-docker/</url><categories><category>Ansible</category><category>Docker</category></categories><tags><tag>Ansible</tag><tag>Docker</tag></tags><content type="html"> Docker-Engine的安装: 利用 MickeyZZC / MiAnsibleRules 中的docker-engine ,参考以下playbook:
#!/usr/bin/env ansible-playbook --- - hosts: all gather_facts: yes sudo: yes roles: - role: docker-engine tags: docker Docker-Container: 参考 MickeyZZC / MiAnsibleRules 其他rules. 每个rules都有变量,可以在自己的ansible项目中给予vars值.</content></entry><entry><title>VPS 记录</title><url>/posts/old/vps_oversea/</url><categories><category>Linux</category></categories><tags><tag>Vps</tag><tag>Shadowsocks</tag></tags><content type="html"> 概述： 分类基于虚拟化
KVM 要想启用 BBR 需要切换内核，所以必须要 KVM 或者 XEN 架构的 VPS。 Openvz 开启 BBR （UML或LKL） 虽说 OpenVZ 在正常情况下是无法使用 BBR 的，但是通过其他一些手段还是能够达到目的。比如UML 和 LKL 。 Docker</content></entry><entry><title>Linode的BBR简单测试</title><url>/posts/old/linode-bbr-test/</url><categories><category>Tcp</category></categories><tags><tag>Tcp</tag></tags><content type="html"><![CDATA[  简单阐述: TCP BBR 致力于解决两个问题： 在有一定丢包率的网络链路上充分利用带宽。非常适合高延迟、高带宽的网络链路。 降低网络链路上的 buffer 占用率，从而降低延迟。非常适合慢速接入网络的用户。 测试目的: 这次的测试主要是针对丢包率.更有说服力的测试请参考 Lawrence Brakmo的BBR Report .
BBR的另一面 测试准备： ADDR01：aaa.aaa.aaa.aaa $ uname -r 4.8.6-x86_64-linode78 ADDR02：bbb.bbb.bbb.bbb # uname -r 4.8.6-x86_64-linode78 测试方式： 模拟丢包1%-30%的场景，分别测试不同内核开启BBR先后的情况。 用到的tc指令：
# 清理tc规则： tc qdisc del root dev eth0 # 模拟1%丢包： tc qdisc add dev eth0 root netem loss 1% # 模拟10%丢包： tc qdisc add dev eth0 root netem loss 10% # 模拟30%丢包： tc qdisc add dev eth0 root netem loss 30% 测试从从ADDR02传数据到ADDR01,ADDR01的内核不变,ADDR02在每次测试都会调整内核重启。 测试过程： 步骤略,test.gz约160MB,过程大致如下: 没有启用BBR的情况，从ADDR02传数据到ADDR01：
$ rsync -ave &#34;ssh -l mickey&#34; --progress test.gz mickey@bbb.bbb.bbb.bbb:/home/mickey/test.gz sending incremental file list test.gz 166042909 100% 3.27MB/s 0:00:48 (xfer#1, to-check=0/1) sent 166063274 bytes received 31 bytes 3288382.28 bytes/sec total size is 166042909 speedup is 1.00 测试数据比对: 4.8.6-x86_64-linode78 4.9.15-x86_64-linode78 非linode的官方4.10内核(generic) 没有启动BBR正常情况 3.27MB/s 3.36MB/s 没有测试 启动BBR正常情况 没有测试 3.45MB/s 2.31MB/s 启动BBR丢包1% 3.19MB/s 没有测试 没有测试 启动BBR丢包10% 没有测试 3.21MB/s 2.81MB/s 启动BBR丢包30% 97.30kB/s(在20分钟内没有传输完成中断得到的最后结果) 1.35MB/s 1.15MB/s 测试总结和当时情况(以上述结果来总结): linode自己编译的内核有明显针对性优化,效果比较明显. 启动bbr后在丢包30%的情况下还能完成传输,bbr的效果也比较明显; 4.10内核选择了generic没有选择lowlatency. 本来还打算测50%的丢包.但是50%设置后几乎无法远程操作ADDR01而放弃测试. 附录： centos7官方内核的升级方法： 升级内核: rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm yum --enablerepo=elrepo-kernel install kernel-ml -y 更新启动 egrep ^menuentry /etc/grub2.cfg | cut -f 2 -d \&#39; grub2-set-default 0 #default 0表示第一个内核设置为默认运行, 选择最新内核就对了 reboot 开启BBR： modprobe tcp_bbr echo &#34;net.core.default_qdisc=fq&#34; &gt;&gt; /etc/sysctl.conf echo &#34;net.ipv4.tcp_congestion_control=bbr&#34; &gt;&gt; /etc/sysctl.conf sysctl -p   ]]></content></entry><entry><title>树莓派 RaspberryPi docker集群</title><url>/posts/old/rasp_pi_docker/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag><tag>Arm</tag></tags><content type="html"><![CDATA[  概述： 参考 Hypriot 的博客，我买了1块Rasp2代板和2块Rasp3代板。
其中2代默认安装了 Hypriot 的系统。3代板如果您有兴趣可以自己参考 《Building a 64bit Docker OS for the Raspberry Pi 3》 这篇文章编译一套64bit的系统。也可以直接下载作者的 已编译好镜像地址 中压缩包。
网络的问题： 日常的升级或者包安装之类的情况，都会遇到墙的问题。为了避免经常为墙而烦恼的情况，有必要给控制网络出口的路由做些调整。参考 《Shadowsocks + ChnRoute 实现 OpenWRT / LEDE 路由器自动翻墙》 解决墙的烦恼，因为这个不是这篇文的重点，具体细节略。
给每个arm板子在路由上赋予一个静态IP地址。
系统： OS细节： 个人习惯调整一下环境，如zsh,vim等，可以考虑弄个ansible-playbook或者shell脚本来简化一下。 # 调整默认文本工具为vim $ update-alternatives --config editor $ dpkg-reconfigure locales # 新建自己的账号并加入到docker组 $ usermod a -G docker xxx # 这步对集群很重要，修改设备的名字，否则后期加入集群会报错 $ sed -i &#34;s/black-pearl/node01-pearl/&#34; /boot/device-init.yaml /etc/hostname Kubernetes(本来我想用这个来管理的，但是我的pi2的docker是最新ce版本，kubeadmin提示不支持。) 参考 《Setup Kubernetes on a Raspberry Pi Cluster easily the official way!》 添加源： $ curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - $ echo &#34;deb http://apt.kubernetes.io/ kubernetes-xenial main&#34; &gt; /etc/apt/sources.list.d/kubernetes.list 安装kubeadm $ apt-get update &amp;&amp; apt-get install -y kubeadm 初始化主节点 $ kubeadm init --pod-network-cidr 10.244.0.0/16 略。。。 Swarm(选择了这个) 初始化pi2 $ docker swarm init 把得到的token信息给每个节点接入来 $ docker swarm join \ --token SWMTKN-1-5pm7otmn3vt9bmjhdfdk2hhgxp1zm9wfcyebl7x4dlkbbqujke-4fmuuxxxxxxxxxhiyqem \ 192.168.xx.2:2377 输出一下node信息： $ docker node ls ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS mbosd1usr6vfoj2p9zyw6zhau node01-pearl Ready Active sc4vtm5fqbdet8k4vrr38x1fo * master-pearl Ready Active Leader v8uxeq9pc8pzlciing7lol16e node02-pearl Ready Active   ]]></content></entry><entry><title>ARM的点点滴滴记录</title><url>/posts/old/arm-board-note/</url><categories><category>Arm</category></categories><tags><tag>Arm</tag><tag>Linux</tag></tags><content type="html"><![CDATA[  Raspberry Pi 我用树莓派搭建docker集群环境，参考 Hypriot 的博客
CubieBoard 安装docker 选择Hypriot(截止到2017年3月版本是docker 1.11.1) Install dependencies $ apt-get install -y apt-transport-https Add respository key $ wget -q https://packagecloud.io/gpg.key -O - | sudo apt-key add - Add repository $ echo &amp;#39;deb https://packagecloud.io/Hypriot/Schatzkiste/debian/ jessie main&amp;#39; | sudo tee /etc/apt/sources.list.d/hypriot.list $ apt-get update Install Hypriot $ apt-get install -y docker-hypriot $ systemctl enable docker 选择Dockerproject (随官方更新，截止2017年3月，版本17.03-ce) Install dependencies $ sudo apt-get update $ sudo apt-get install apt-transport-https ca-certificates Add repository $ sudo apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D 用下面的命令将 APT 源添加到 source.list（将其中的 替换为下表“表一：dockerproject 对应表”的值）：
$ echo &amp;#34;&amp;lt;REPO&amp;gt;&amp;#34; | sudo tee /etc/apt/sources.list.d/docker.list Install Docker-Engine $ apt-get update $ apt-get install -y docker-engine …  ]]></content></entry><entry><title>GitHub博客的搭建（docker-hexo）</title><url>/posts/old/blog_mickeyzzc/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag><tag>Node</tag></tags><content type="html"><![CDATA[  工具选用了 hexo ， 主题选择了 NexT.Mist 。 CDN选择了 CloudFlare 。
过程（详细步骤请参考官方网站，这里只提及过程中的注意点）： 参考 hexo 在本地安装，我用的是debian系统。 在中国境内经常会遇到墙的问题，建议使用 淘宝的cnpm 。
$ npm install -g cnpm --registry=https://registry.npm.taobao.org 然后使用cnpm命令安装hexo-cli
$ cnpm install -g hexo-cli 个性化的自己的配置，并且在github上建立xxx.github.io库。 在 hexo 的本地目录source下初始化git库， 并在自己的git库上管理。
CDN和HTTPS的构建： 在 hexo 的本地目录public下创建CNAME文件，内容为你的域名。 注册 CloudFlare ， 把域名的NS切换到 CloudFlare 管理。 在 CloudFlare 的Crypto页中， SSL设置为Flexible。这将允许CDN到github pages之间的访问为http。 CloudFlare 提供Page Rules功能， 可设置路由规则。通过规则中的Always use https选项，可以将用户强制跳转到https。 http://*.mickeyzzc.tech/* 使用Docker构建 利用DOCKERFILE 构建一个本地使用的hexo镜像. # MAINTAINER MickeyZZC &lt;xxx@xxx.com&gt; # DOCKER-VERSION 1.13.0 # FROM node:6 MAINTAINER MickeyZZC &lt;xxx@xxx.com&gt; RUN cp -f /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \ &amp;&amp; npm install -g cnpm --registry=https://registry.npm.taobao.org \ &amp;&amp; cnpm install -g hexo-cli \ &amp;&amp; mkdir -p /home/hexo/public \ &amp;&amp; cd /home/hexo \ &amp;&amp; hexo init \ &amp;&amp; git clone https://github.com/iissnan/hexo-theme-next themes/next \ &amp;&amp; cnpm install hexo-deployer-git --save \ &amp;&amp; git clone https://git.oschina.net/MickeyZZC/MiZDoc.git mickeyblog \ &amp;&amp; cp -f mickeyblog/hexo_config/_config.yml _config.yml \ &amp;&amp; cp -f mickeyblog/hexo_config/themes_next_config.yml themes/next/_config.yml \ &amp;&amp; cp -f mickeyblog/hexo_config/gitconfig.cfg ./.gitconfig \ &amp;&amp; cp -rf mickeyblog/hexo_source/* source/ \ &amp;&amp; rm -rf mickeyblog source/_posts/hello-world.md \ &amp;&amp; chown -R node.node /home/hexo &amp;&amp; chown -R node /usr/local/lib/node_modules/ \ &amp;&amp; echo &#34;blog.mickeyzzc.tech&#34; &gt; /home/hexo/public/CNAME \ &amp;&amp; hexo generate \ &amp;&amp; chown -R node.node /home/hexo ENV HOME /home/hexo WORKDIR /home/hexo EXPOSE 4000 USER node CMD [&#34;hexo&#34;,&#34;server&#34;] 构建后本地运行来调试hexo docker run --rm -p 4000:4000 \ -v $HOME/migit/miBlog:/home/hexo/source\ -it mickeyzzc/node-hexo 最后打包合并到GIT库管理：   ]]></content></entry><entry><title>跨城区局域网的搭建（基于Docker）</title><url>/posts/old/mi-docker-net/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag><tag>Openvpn</tag></tags><content type="html"><![CDATA[  概述： 管理复杂网络内的系统,有时候需要突破网络限制.有比较多的方案,比如ss5,Shadowsocks,vpn等. 这里提供一种方案是利用 docker-openvpn 实施多重复杂网络内的主机互联,实现利用nginx反向代理各类服务.
概念图： 具体流程： 购买云服务器部署docker 建议购买支持systemctl的Linux系统,比较好管理,并部署docker:
外挂存储格式化为xfs分区; # mkfs.xfs /dev/vdb5 # echo &#34;/dev/vdb5 /mnt/data xfs defaults 1 1&#34; |tee -a /etc/fstab 调整docker的目录,两种方法; 挂载/var/lib/docker目录: # systemctl stop docker # mkdir -p /mnt/data/docker # rsync -aXS /var/lib/docker/. /mnt/data/docker/ # echo &#34;/mnt/data/docker /var/lib/docker none bind 0 0&#34;|tee -a /etc/fstab # mount -a # systemctl start docker 指定具体目录: 在/etc/systemd/system/multi-user.target.wants/docker.service里面修改如下: ExecStart=/usr/bin/dockerd --storage-driver=overlay2 -g /mnt/hhd/docker 安装 docker-openvpn 服务: Pick a name for the $OVPN_DATA data volume container, it will be created automatically. # OVPN_DATA=&#34;ovpn-data&#34; Initialize the $OVPN_DATA container that will hold the configuration files and certificates # docker volume create --name $OVPN_DATA # docker run -v $OVPN_DATA:/etc/openvpn \ --rm kylemanna/openvpn ovpn_genconfig \ -u udp://VPN.SERVERNAME.COM # docker run -v $OVPN_DATA:/etc/openvpn \ --rm -it kylemanna/openvpn ovpn_initpki 如果使用tcp # docker run -v $OVPN_DATA:/etc/openvpn \ --rm kylemanna/openvpn ovpn_genconfig \ -u tcp://VPN.SERVERNAME.COM:1443 Start OpenVPN server process # docker run -v $OVPN_DATA:/etc/openvpn -d \ -p 1194:1194/udp \ --cap-add=NET_ADMIN kylemanna/openvpn OR # docker run -v $OVPN_DATA:/etc/openvpn -d \ -p 1443:1194/tcp \ --cap-add=NET_ADMIN kylemanna/openvpn Running a Second Fallback TCP Container # docker run -v $OVPN_DATA:/etc/openvpn \ --rm -p 1443:1194/tcp \ --privileged kylemanna/openvpn ovpn_run \ --proto tcp Generate a client certificate without a passphrase . Retrieve the client configuration with embedded certificates, &ldquo;CLIENTNAME&quot;可自定义;
# docker run -v $OVPN_DATA:/etc/openvpn \ --rm -it kylemanna/openvpn easyrsa build-client-full CLIENTNAME nopass # docker run -v $OVPN_DATA:/etc/openvpn \ --rm kylemanna/openvpn ovpn_getclient CLIENTNAME &gt; CLIENTNAME.ovpn 增加路由规则 在docker主机上增加一条路由规则,目的是使其他容器可以通过默认的网络来访问到openvpn客户端的节点:
# ip route add 192.168.255.0/24 via $DOCKER_OPENVPN_IP 给客户端配置静态内外IP。 # cat ccd/CLIENTNAME ifconfig-push 192.168.255.10 192.168.255.9 部署前端代理 选择 DOCKER-CADDY 做反向代理: docker run -d \ -v $(pwd)/Caddyfile:/etc/Caddyfile \ -v $HOME/.caddy:/root/.caddy \ -p 80:80 -p 443:443 \ --name caddy \ --link openvpn:openvpn \ abiosoft/caddy CADDY的配置参考： http://git.mickeybee.cn { redir https://git.mickeybee.cn{url} } https://git.mickeybee.cn { gzip proxy / 192.168.xxx.xx:3000 tls xxx@xxx.com { max_certs 10 key_type p256 } } 部署TCP代理 选择 DOCKER-HAPROXY 并部署: docker run -d \ -v $(pwd)/haproxy:/usr/local/etc/haproxy:ro \ -p xxx:xxx -p yyy:yyy \ --name haproxy \ --link openvpn:openvpn \ haproxy 映射后端端口。   ]]></content></entry><entry><title>Tumx + Git + OhMyZsh + VIM</title><url>/posts/old/zsh-tmux-vim-git/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>Tumx</tag><tag>Git</tag><tag>Zsh</tag><tag>Vim</tag></tags><content type="html"><![CDATA[  ubuntu下的环境： 要求： tmux &gt;= 2.1 vim &gt;= 7.3 zsh (oh-my-zsh) git 推荐环境： TMUX(使用 gpakosz 的配置)： 部署方式： $ cd ~ $ git clone https://github.com/gpakosz/.tmux.git $ ln -s -f .tmux/.tmux.conf $ cp .tmux/.tmux.conf.local . $ sudo apt-get install xclip ## Ubuntu下安装xclip来支持跨文件复制粘贴 修改“.tmux.conf” 把以下地方修改： bind -t vi-copy y copy-selection 改为 bind -t vi-copy y copy-pipe &ldquo;xclip -sel clip -i&rdquo;
如果tmux &lt;1.8 请修改如下：
# copy &amp; paste between tmux and x clipboard bind C-p run-shell &quot;tmux set-buffer \&quot;$(xclip -o)\&quot;; tmux paste-buffer&quot; bind C-y run-shell &quot;tmux show-buffer | xclip -sel clip -i&quot; 修改“.tmux.conf.local”把以下地方注释去掉： # set -g status-keys vi # set -g mode-keys vi
GIT： 日常都会用到几个git库，有包含同事的和自己的。管理起来都比较麻烦，但是利用到git子模块会比较方便。
$ mkdir xxxx $ git init $ git remote add origin ssh://git@git.xxx.net/mickey/xxxx.git $ git submodule add ssh://git@git.xxx.net/mickey/tttt.git xxxx $ git add -A $ git commit -m &#34;add submodule tttt&#34; $ git push --set-upstream origin master 当需要全部更新的时候：
$ git submodule foreach git pull 初始化:
➜ ~ git clone ssh://git@git.xxx.net/mickey/xxxx.git ➜ ~ cd xxxx ➜ xxxx git:(master) git submodule init ➜ xxxx git:(master) git submodule sync ➜ xxxx git:(master) git submodule update ➜ xxxx git:(master) git submodule foreach git pull origin master   ]]></content></entry></search>