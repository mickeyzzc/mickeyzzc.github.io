<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>基于 ESP01 主板的温湿度监控开发</title><url>/posts/iot/esp-01-dht11/</url><categories><category>IOT</category></categories><tags><tag>IOT</tag><tag>Arduino</tag></tags><content type="html"><![CDATA[  引言 在物联网应用中，温湿度监控是一个常见且重要的需求。ESP01 作为一款低成本、低功耗的 Wi-Fi 模块，为实现温湿度监控提供了一个便捷的解决方案。本文将详细介绍如何使用 ESP01 主板进行温湿度监控开发，包括硬件连接、代码实现和功能解析。
硬件准备 ESP01 主板：核心控制模块，负责数据采集和网络通信。 DHT 温湿度传感器：用于测量环境的温度和湿度。 杜邦线：用于连接 ESP01 和 DHT 传感器。 将 DHT 传感器的 VCC 引脚连接到 ESP01 的 3.3V 引脚，GND 引脚连接到 GND，数据引脚连接到 ESP01 的指定引脚（代码中为 DHTPIN）。
代码实现 引入必要的库 1 2 3 4 5 6 7 8 9 #include &lt;ESP8266WiFi.h&gt; #include &lt;WiFiUdp.h&gt; #include &lt;NTPClient.h&gt; #include &lt;PubSubClient.h&gt; #include &lt;ESP8266WebServer.h&gt; #include &lt;ArduinoJson.h&gt; #include &lt;DHT.h&gt; #include &#34;app_config.h&#34; #include &#34;wifi_config.h&#34; 这些库分别用于处理 Wi-Fi 连接、NTP 时间同步、MQTT 通信、Web 服务器、JSON 数据处理和 DHT 传感器读取。
初始化相关对象 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // 创建一个UDP对象用于NTP客户端 WiFiUDP ntpUDP; NTPClient timeClient(ntpUDP, ntpserver, 8 * 3600, 60000); // 创建WiFi和MQTT客户端对象 WiFiClient espClient; PubSubClient client(espClient); uint32_t delayMS; unsigned long globalPreviousMillis = millis(); unsigned long globalCurrentMillis = millis(); String readings; DHT dht(DHTPIN, DHTTYPE); ESP8266WebServer server(80); 这里初始化了 NTP 客户端、WiFi 客户端、MQTT 客户端、DHT 传感器对象和 Web 服务器对象。
重连 MQTT 服务器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 void reconnect() { unsigned long previousMillis = millis(); unsigned long rebootMillis = millis(); while (!client.connected()) { unsigned long currentMillis = millis(); if (currentMillis - previousMillis &gt;= 1500) { if (currentMillis - rebootMillis &gt;= 5000) { Serial.println(&#34;exit to try.&#34;); break; } previousMillis = currentMillis; } Serial.print(&#34;Attempting MQTT connection...&#34;); // Generate a random client ID String clientId = &#34;ESP32Client-&#34;; clientId += String(WiFi.macAddress()); Serial.print(clientId.c_str()); if (client.connect(clientId.c_str())) { Serial.println(&#34; ... connected&#34;); } else { Serial.print(&#34; ... failed, rc=&#34;); Serial.print(client.state()); Serial.println(&#34; try again in 1 seconds&#34;); delay(1000); } } } 该函数用于在 MQTT 连接断开时尝试重新连接，设置了重试时间和退出条件。
获取传感器数据并发布到 MQTT 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 String getReadingsSensor () { // 创建一个动态分配的JSON文档 DynamicJsonDocument sensordoc(1024); JsonObject info = sensordoc.createNestedObject(&#34;info&#34;); timeClient.update(); int epochTimel =timeClient.getEpochTime(); info[&#34;board_type&#34;] = boardType; info[&#34;ip&#34;] = WiFi.localIP().toString(); info[&#34;mac&#34;] = WiFi.macAddress(); info[&#34;utc&#34;] = epochTimel; info[&#34;name&#34;] = nodeName; JsonObject sensor = sensordoc.createNestedObject(&#34;sensor&#34;); JsonObject sensorTemp = sensor.createNestedObject(&#34;ths&#34;); sensorTemp[&#34;name&#34;] = dhtName; float humidity = dht.readHumidity(); float temperature = dht.readTemperature(); float fahrenheit = dht.readTemperature(true); if (isnan(humidity) || isnan(temperature) || isnan(fahrenheit)) { Serial.println(F(&#34;Failed to read from DHT sensor!&#34;)); } else { float hif = dht.computeHeatIndex(fahrenheit, humidity); float hic = dht.computeHeatIndex(temperature, humidity, false); Serial.print(F(&#34;Humidity: &#34;)); Serial.print(humidity); Serial.print(F(&#34;% Temperature: &#34;)); Serial.print(temperature); Serial.print(F(&#34;°C &#34;)); Serial.print(fahrenheit); Serial.print(F(&#34;°F Heat index: &#34;)); Serial.print(hic); Serial.print(F(&#34;°C &#34;)); Serial.print(hif); Serial.println(F(&#34;°F&#34;)); sensorTemp[&#34;temperature&#34;] = temperature; sensorTemp[&#34;humidity&#34;] = humidity; sensorTemp[&#34;fahrenheit&#34;] = fahrenheit; } serializeJson(sensordoc, readings); // 发布数据到MQTT主题 client.publish(&#34;sensor/data&#34;, readings.c_str()); return readings; } 此函数读取 DHT 传感器的温湿度数据，将其封装成 JSON 格式，并通过 MQTT 发布到指定主题。
处理 API 请求 1 2 3 4 5 6 7 8 void handleAPI() { String result; result += &#34;#Esp-01 API \n&#34;; String msg = getReadingsSensor(); result += msg + &#34;\n&#34;; server.sendHeader(&#34;Cache-Control&#34;, &#34;no-cache&#34;); server.send(200, &#34;application/json; charset=utf-8&#34;, result); } 该函数处理 /api/sensor 的 HTTP GET 请求，返回传感器数据的 JSON 格式。
初始化设置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 void setup() { Serial.begin(115200); dht.begin(); lastConnectTime = millis(); WiFi.mode(WIFI_STA); WiFi.begin(ssid, password); unsigned long previousMillis = millis(); unsigned long rebootMillis = millis(); while (WiFi.status() != WL_CONNECTED) { unsigned long currentMillis = millis(); if (currentMillis - previousMillis &gt;= 15000) { if (currentMillis - rebootMillis &gt;= 50000) { Serial.println(&#34;reboot now.&#34;); ESP.restart(); } Serial.println(&#34;retry now.&#34;); WiFi.disconnect(); WiFi.reconnect(); previousMillis = currentMillis; } delay(500); Serial.print(&#34;.&#34;); } Serial.println(&#34;&#34;); Serial.print(&#34;Connected to &#34;); Serial.println(ssid); Serial.print(&#34;IP address: &#34;); Serial.println(WiFi.localIP()); server.on(F(&#34;/&#34;), []() { server.send(200, &#34;text/plain&#34;, &#34;hello from esp32!&#34;); }); delayMS = 15000; client.setServer(mqttServer, mqttPort); client.setKeepAlive(60); // 设置心跳间隔为60秒 client.setBufferSize(2048); server.on(&#34;/api/sensor&#34;, HTTP_GET, handleAPI); server.begin(); Serial.println(&#34;HTTP server started&#34;); globalPreviousMillis = millis(); globalCurrentMillis = millis(); getReadingsSensor(); } setup 函数完成串口初始化、DHT 传感器初始化、Wi-Fi 连接、MQTT 服务器设置和 Web 服务器启动等操作。
主循环 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 void loop() { server.handleClient(); WiFiStatusHandle(); globalCurrentMillis = millis(); if (globalCurrentMillis - globalPreviousMillis &gt;= delayMS) { if (!client.connected()) { reconnect(); } client.loop(); // 假设这是从传感器读取的数据 getReadingsSensor(); // 发布数据到MQTT主题 //client.publish(&#34;sensor/data&#34;, readings.c_str()); Serial.println(client.state()); Serial.println(client.getBufferSize()); Serial.println(client.getWriteError()); globalPreviousMillis = globalCurrentMillis; } delay(200); //allow the cpu to switch to other tasks } loop 函数不断处理 Web 服务器请求，检查 Wi-Fi 状态，每隔一定时间读取传感器数据并发布到 MQTT 服务器。
功能解析 温湿度数据采集 通过 DHT 传感器读取环境的温度和湿度数据，并计算出华氏温度和热指数。
网络通信 Wi-Fi 连接：ESP01 连接到指定的 Wi-Fi 网络，获取 IP 地址。
MQTT 通信：将采集到的温湿度数据封装成 JSON 格式，通过 MQTT 协议发布到指定主题。
Web 服务器：提供一个简单的 Web 服务器，处理 /api/sensor 的 HTTP GET 请求，返回传感器数据。
错误处理和重连机制 在 Wi-Fi 连接失败或 MQTT 连接断开时，会尝试重新连接，并且设置了超时重启机制，确保系统的稳定性。
总结 通过以上步骤，我们成功使用 ESP01 主板实现了温湿度监控功能。该系统可以实时采集环境的温湿度数据，并通过 MQTT 协议将数据传输到服务器，同时提供了一个简单的 Web API 供外部访问。这个方案成本低、易于实现，适用于各种温湿度监控场景。
  ]]></content></entry><entry><title>eBPF系列之：DeepFlow 扩展协议解析实践（MongoDB协议与Kafka协议）</title><url>/posts/ebpf/deepflow-agent-proto-dev/</url><categories><category>eBPF</category></categories><tags><tag>Tcp</tag><tag>DeepFlow</tag><tag>eBPF</tag></tags><content type="html"><![CDATA[   概述： 如何分析一个协议(MongoDB) 协议文档的分析思路 MongoDB协议操作码说明表 对最常见的操作码OP_MSG分析 在DeepFlow Agent扩展一个协议解析采集 DeepFlow Agent的开发文档概要 代码指引 定义一个协议，并用一个常量标识。 为新协议准备解析逻辑 定义结构体 实现 L7ProtocolParserInterface 利用Wasm插件扩展DeepFlow的协议采集 Kafka协议分析 Kafka的Header和Data概览 Kafka的Fetch API Kafka的Produce API Kafka协议DeepFlow Agent原生解码 DeepFlow Agent的 Wasm 插件 Wasm Go SDK 的框架 插件代码指引 结语 原生Rust扩展 Wasm插件扩展 附录 概述： MongoDB 目前使用广泛，但是缺乏有效的可观测能力。 DeepFlow 在可观测能力上是很优秀的解决方案，但是却缺少了对 MongoDB 协议的支持。 该文是为 DeepFlow 扩展了 MongoDB 协议解析，增强 MongoDB 生态的可观测能力，简要描述了从协议文档分析到在 DeepFlow 内实现代码解析的过程拆解。
如何分析一个协议(MongoDB) 协议文档的分析思路 首先要从官方网站找到协议解析的文档，在协议文档 《mongodb-wire-protocol#standard-message-header》 中，可以看到MongoDB的协议头结构体描述如下：
1 2 3 4 5 6 7 struct MsgHeader { int32 messageLength; // total message size, including this int32 requestID; // identifier for this message int32 responseTo; // requestID from the original request // (used in responses from the database) int32 opCode; // message type } 上述结构代码理解为下图所示：
注意，在协议文档 《mongodb-wire-protocol》 有一段说明，MongoDB协议是用了字节小端顺序。
Byte Ordering All integers in the MongoDB wire protocol use little-endian byte order: that is, least-significant
接下来从实际的抓包看一下实际的数据是长什么样子的。 1 2 3 4 5 6 7 8 9 10 11 12 0000 a3 00 00 00 0a 50 88 48 23 00 00 00 dd 07 00 00 0010 00 00 00 00 00 8e 00 00 00 01 6f 6b 00 00 00 00 0020 00 00 00 f0 3f 11 6f 70 65 72 61 74 69 6f 6e 54 0030 69 6d 65 00 01 00 00 00 bc 1d c3 64 03 24 63 6c 0040 75 73 74 65 72 54 69 6d 65 00 58 00 00 00 11 63 0050 6c 75 73 74 65 72 54 69 6d 65 00 01 00 00 00 bc 0060 1d c3 64 03 73 69 67 6e 61 74 75 72 65 00 33 00 0070 00 00 05 68 61 73 68 00 14 00 00 00 00 29 12 d4 0080 7f 78 52 55 42 04 29 2f b7 36 85 39 c1 47 66 05 0090 de 12 6b 65 79 49 64 00 01 00 00 00 8c d2 e4 63 00a0 00 00 00 上述的抓包数据简单拆解到如下信息：
字段messageLength为a3 00 00 00 ：即 消息长度为 a3 字段requestID为0a 50 88 48：即 请求ID为4888500a 字段responseTo为23 00 00 00：即 对ID为23的响应 字段opCode为dd 07 00 00：即 命令号为 7dd，十进制是2013，对应协议文档中的OP_MSG指令。 MongoDB协议操作码说明表 操作码名称 操作码 操作码说明 额外说明 OP_COMPRESSED 2012 使用压缩 OP_MSG 2013 Send a message using the standard format. Used for both client requests and database replies. OP_REPLY 1 通过responseTo指定响应客户端请求。 Deprecated in MongoDB 5.0. Removed in MongoDB 5.1. OP_UPDATE 2001 更新文档 Deprecated in MongoDB 5.0. Removed in MongoDB 5.1. OP_INSERT 2002 插入文档 Deprecated in MongoDB 5.0. Removed in MongoDB 5.1. RESERVED 2003 略 OP_QUERY 2004 查询文档 Deprecated in MongoDB 5.0. Removed in MongoDB 5.1. OP_GET_MORE 2005 略 Deprecated in MongoDB 5.0. Removed in MongoDB 5.1. OP_DELETE 2006 删除文档 Deprecated in MongoDB 5.0. Removed in MongoDB 5.1. OP_KILL_CURSORS 2007 略 Deprecated in MongoDB 5.0. Removed in MongoDB 5.1. 对最常见的操作码OP_MSG分析 从协议文档 《mongodb-wire-protocol#op_msg》 查看OP_MSG的结构体
1 2 3 4 5 6 OP_MSG { MsgHeader header; // standard message header uint32 flagBits; // message flags Sections[] sections; // data sections optional&lt;uint32&gt; checksum; // optional CRC-32C checksum } OP_MSG需要关注的解码内容在Sections，只需要判断kind为0和1的情况，其中：
0：后面直接用BSON解码； 1：先偏移int32和c_string占用的byte后，用BSON解码后面的内容 从实际抓包看一下原始数据。如下所示，MongoDB协议的操作码OP_MSG内容从第十六（从0开始数，后续文档统一按此规律）字节开始。 1 2 3 4 5 6 7 8 9 10 11 12 13 0000 a3 00 00 00 0a 50 88 48 23 00 00 00 dd 07 00 00 0010 00 00 00 00 00 8e 00 00 00 01 6f 6b 00 00 00 00 0020 00 00 00 f0 3f 11 6f 70 65 72 61 74 69 6f 6e 54 0030 69 6d 65 00 01 00 00 00 bc 1d c3 64 03 24 63 6c 0040 75 73 74 65 72 54 69 6d 65 00 58 00 00 00 11 63 0050 6c 75 73 74 65 72 54 69 6d 65 00 01 00 00 00 bc 0060 1d c3 64 03 73 69 67 6e 61 74 75 72 65 00 33 00 0070 00 00 05 68 61 73 68 00 14 00 00 00 00 29 12 d4 0080 7f 78 52 55 42 04 29 2f b7 36 85 39 c1 47 66 05 0090 de 12 6b 65 79 49 64 00 01 00 00 00 8c d2 e4 63 00a0 00 00 00 不需要关心字段flagBits，偏移4个字节后从第四个字节判断字段kind类型。由此判断后面为BSON结构数据。
到这里我们已经基本了解到MongoDB协议的数据结构和解码思路了，接下来我们开始在DeepFlow Agent中尝试实现解码观察。
在DeepFlow Agent扩展一个协议解析采集 DeepFlow Agent的开发文档概要 前提，DeepFlow Agent的原生开发需要掌握Rust语言的基础开发能力。 接下来先参考官方文档 《HOW_TO_SUPPORT_YOUR_PROTOCOL_CN》 了解几个关键信息
L7Protocol 用于标识协议常量 源码位置：deepflow/agent/crates/public/src/l7_protocol.rs
L7ProtocolParser 主要用于协议判断和解析出 L7ProtocolInfo(七层协议的基础结构信息) 源码位置：deepflow/agent/src/common/l7_protocol_log.rs L7ProtocolInfo 由 L7ProtocolParser 解析出来，并且用于后续会话聚合 源码位置：deepflow/agent/src/common/l7_protocol_info.rs
L7ProtocolInfoInterface 七层协议结构L7ProtocolInfo 都需要实现这个接口来处理特征逻辑 源码位置：deepflow/agent/src/common/l7_protocol_info.rs
L7ProtocolSendLog 统一发送到 deepflow-server 的结构 源码位置：deepflow/agent/src/flow_generator/protocol_logs/pb_adapter.rs
在 deepflow-agent 中开发的大致步骤：
在 “deepflow/agent/crates/public/src/l7_protocol.rs” 添加对应协议名称和协议号。 L7ProtocolParser::parse_payload() 需要返回 L7ProtocolInfo，所以需要先定义一个结构，实现 L7ProtocolInfoInterface 接口并且添加到 L7ProtocolInfo 这个枚举。 实现 L7ProtocolParserInterface 接口，并添加到“deepflow/agent/src/common/l7_protocol_log.rs”中的 impl_protocol_parser! 宏。 在 deepflow-server 中只需增加一个常量用于搜索提示即可。 代码指引 定义一个协议，并用一个常量标识。 源码位置：deepflow/agent/crates/public/src/l7_protocol.rs，Agent 通过遍历所有支持协议判断一个流的应用层协议。 这里说明一下，由于业界的通用应用协议没有一个约束字段来定义应用协议类型，所以在大量网络包是通过遍历已知协议解码逻辑来判断应用层协议的。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 pub enum L7Protocol { #[num_enum(default)] Unknown = 0, Other = 1, // HTTP Http1 = 20, Http2 = 21, Http1TLS = 22, Http2TLS = 23, // RPC Dubbo = 40, Grpc = 41, SofaRPC = 43, FastCGI = 44, // SQL MySQL = 60, PostgreSQL = 61, // NoSQL Redis = 80, + MongoDB = 81, // MQ Kafka = 100, MQTT = 101, // INFRA DNS = 120, Custom = 127, Max = 255, } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 impl From&lt;String&gt; for L7Protocol { fn from(l7_protocol_str: String) -&gt; Self { let l7_protocol_str = l7_protocol_str.to_lowercase(); match l7_protocol_str.as_str() { &#34;http&#34; | &#34;https&#34; =&gt; Self::Http1, &#34;dubbo&#34; =&gt; Self::Dubbo, &#34;grpc&#34; =&gt; Self::Grpc, &#34;fastcgi&#34; =&gt; Self::FastCGI, &#34;custom&#34; =&gt; Self::Custom, &#34;sofarpc&#34; =&gt; Self::SofaRPC, &#34;mysql&#34; =&gt; Self::MySQL, + &#34;mongodb&#34; =&gt; Self::MongoDB, &#34;postgresql&#34; =&gt; Self::PostgreSQL, &#34;redis&#34; =&gt; Self::Redis, &#34;kafka&#34; =&gt; Self::Kafka, &#34;mqtt&#34; =&gt; Self::MQTT, &#34;dns&#34; =&gt; Self::DNS, _ =&gt; Self::Unknown, } } } 为新协议准备解析逻辑 定义结构体 在“deepflow/agent/src/flow_generator/protocol_logs/”该路径下找一个目录建立相关的协议解析逻辑代码文件，该案例的代码文件放在上述目录下的“sql/mongo.rs”。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 pub struct MongoDBInfo { msg_type: LogMessageType, #[serde(rename = &#34;req_len&#34;)] pub req_len: u32, #[serde(rename = &#34;resp_len&#34;)] pub resp_len: u32, //// 参考“deepflow/agent/src/flow_generator/protocol_logs/pb_adapter.rs” // 准备要处理的结构体。 // 其中“request_id”、“response_id”、“op_code”和“op_code_name”是 // 从mongodb header解析出来的关键信息。 #[serde(rename = &#34;request_id&#34;)] pub request_id: u32, #[serde(rename = &#34;response_id&#34;)] pub response_id: u32, #[serde(rename = &#34;op_code&#34;)] pub op_code: u32, #[serde(skip)] pub op_code_name: String, //// “request”、“response”和“response_code”是 // 从mongodb协议主体内容解析出来的所需信息。 #[serde(rename = &#34;request_resource&#34;] pub request: String, #[serde(skip)] pub response: String, #[serde(rename = &#34;response_code&#34;] pub response_code: i32, //// #[serde(rename = &#34;response_status&#34;)] pub status: L7ResponseStatus, } 实现 L7ProtocolParserInterface 先看源码结构逻辑（以下只显示需处理函数，不需处理的保留默认逻辑即可） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 #[enum_dispatch] pub trait L7ProtocolParserInterface { fn check_payload(&amp;mut self, payload: &amp;[u8], param: &amp;ParseParam) -&gt; bool; // 协议解析 fn parse_payload(&amp;mut self, payload: &amp;[u8], param: &amp;ParseParam) -&gt; Result&lt;L7ParseResult&gt;; // 返回协议号和协议名称，由于的bitmap使用u128，所以协议号不能超过128. // 其中 crates/public/src/l7_protocol.rs 里面的 pub const L7_PROTOCOL_xxx 是已实现的协议号. // =========================================================================================== // return protocol number and protocol string. because of bitmap use u128, so the max protocol number can not exceed 128 // crates/public/src/l7_protocol.rs, pub const L7_PROTOCOL_xxx is the implemented protocol. fn protocol(&amp;self) -&gt; L7Protocol; // l4是tcp时是否解析，用于快速过滤协议 // ============================== // whether l4 is parsed when tcp, use for quickly protocol filter fn parsable_on_tcp(&amp;self) -&gt; bool { true } // l4是udp是是否解析，用于快速过滤协议 // ============================== // whether l4 is parsed when udp, use for quickly protocol filter fn parsable_on_udp(&amp;self) -&gt; bool { true } // return perf data fn perf_stats(&amp;mut self) -&gt; Option&lt;L7PerfStats&gt;; } 解码协议的第一步是如何识别协议，代码中需处理 L7ProtocolParserInterface::check_payload()逻辑
定义MongoDB协议头并解码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // 定义MongoDB协议头结构体，并对必要信息字段一一解码 #[derive(Clone, Debug, Default, Serialize)] pub struct MongoDBHeader { length: u32, request_id: u32, response_to: u32, op_code: u32, op_code_name: String, } impl MongoDBHeader { fn decode(&amp;mut self, payload: &amp;[u8]) -&gt; isize { // 对payload前16位以MongoDBHeader结构解码，判断是否符合MongoDB的协议 } fn is_request(&amp;self) -&gt; bool { // 解码op_code判断是否request } pub fn get_op_str(&amp;self) -&gt; &amp;&#39;static str { // 解码op_code出对应文本描述 } } 在L7ProtocolParserInterface::check_payload()调用MongoDB协议头解码逻辑 在此过程，把protocol(&amp;self)和parsable_on_udp(&amp;self)也一并处理。 1 2 3 4 5 6 7 8 9 10 11 12 impl L7ProtocolParserInterface for MongoDBLog { fn check_payload(&amp;mut self, payload: &amp;[u8], param: &amp;ParseParam) -&gt; bool { let mut header = MongoDBHeader::default(); header.decode(payload); return header.is_request(); } fn protocol(&amp;self) -&gt; L7Protocol { L7Protocol::MongoDB } // udp协议的跳过解码 fn parsable_on_udp(&amp;self) -&gt; bool {false} } 第一步的效果展示 到这一步的解码将会得到如下展示效果，接下来还需要对具体的协议操作码做进一步解码。 解码协议的第二步是对关键指令定义结构体和解码接口逻辑实现，对应处理是L7ProtocolParserInterface::parse_payload()代码实现，这里以OP_MSG为例
定义OP_MSG操作码的结构体并解码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #[derive(Clone, Debug, Default, Serialize)] pub struct MongoOpMsg { flag: u32, sections: Sections, checksum: Option&lt;u32&gt;, } impl MongoOpMsg { fn decode(&amp;mut self, payload: &amp;[u8]) -&gt; Result&lt;bool&gt; { // 略过偏移逻辑 let _ = sections.decode(&amp;payload); self.sections = sections; Ok(true) } } 对OP_MSG操作码中业务需要关注的字段Sections做进一步解码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #[derive(Clone, Debug, Default, Serialize)] struct Sections { kind: u8, kind_name: String, // kind: 0 mean doc doc: Document, // kind: 1 mean body size: Option&lt;i32&gt;, c_string: Option&lt;String&gt;, } impl Sections { pub fn decode(&amp;mut self, payload: &amp;[u8]) -&gt; Result&lt;bool&gt; { match self.kind { 0 =&gt; {// Body} 1 =&gt; {// Doc} 2 =&gt; {// Internal} _ =&gt; {// Unknown} } Ok(true) } } 处理 L7ProtocolParserInterface::parse_payload，返回 L7ProtocolInfo 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #[derive(Clone, Debug, Default, Serialize)] pub struct MongoDBLog { info: MongoDBInfo, #[serde(skip)] perf_stats: Option&lt;L7PerfStats&gt;, } impl L7ProtocolParserInterface for MongoDBLog { fn parse_payload(&amp;mut self, payload: &amp;[u8], param: &amp;ParseParam) -&gt; Result&lt;L7ParseResult&gt; { let mut info = MongoDBInfo::default(); self.parse(payload, param.l4_protocol, param.direction, &amp;mut info)?; // 解码得到L7ProtocolInfo } } impl MongoDBLog { fn parse(&amp;mut self,payload:&amp;[u8],proto:IpProtocol,dir:PacketDirection,info:&amp;mut MongoDBInfo,)-&gt; Result&lt;bool&gt; { // 解码指令获取请求和响应等信息} // command decode match info.op_code { _OP_MSG if payload.len() &gt; _MSG_DOC_SECTION_OFFSET =&gt; { // OP_MSG let mut msg_body = MongoOpMsg::default();	// TODO: Message Flags msg_body.decode(&amp;payload[_MSG_DOC_SECTION_OFFSET..])?; } } } } 为MongoDBInfo实现L7ProtocolInfoInterface 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 impl L7ProtocolInfoInterface for MongoDBInfo { fn session_id(&amp;self) -&gt; Option&lt;u32&gt; { // 这里返回流标识id，例如 http2 返回 streamid，dns 返回 transaction id，如果没有就返回 None } fn merge_log(&amp;mut self, other: L7ProtocolInfo) -&gt; Result&lt;()&gt; { // 这里的self必定是请求，other必定是响应 if let L7ProtocolInfo::MongoDBInfo(other) = other { self.merge(other); } Ok(()) } fn app_proto_head(&amp;self) -&gt; Option&lt;AppProtoHead&gt; { // 这里返回一个 AppProtoHead 结构，返回 None 直接丢弃这段数据 Some(AppProtoHead { proto: L7Protocol::MongoDB, }) } fn is_tls(&amp;self) -&gt; bool { self.is_tls } } 为MongoDBInfo实现L7ProtocolSendLog 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 impl From&lt;MongoDBInfo&gt; for L7ProtocolSendLog { fn from(f: MongoDBInfo) -&gt; Self { let log = L7ProtocolSendLog { // 这里需要把 info 转换成统一的发送结构 L7ProtocolSendLog }; return log; } } // 参考源码来自：deepflow/agent/src/flow_generator/protocol_logs/pb_adapter.rs pub struct L7ProtocolSendLog { pub req_len: Option&lt;u32&gt;, pub resp_len: Option&lt;u32&gt;, pub row_effect: u32, pub req: L7Request, pub resp: L7Response, pub version: Option&lt;String&gt;, pub trace_info: Option&lt;TraceInfo&gt;, pub ext_info: Option&lt;ExtendedInfo&gt;, } 把实现L7ProtocolParserInterface的接口，添加到deepflow/agent/src/common/l7_protocol_log.rs中的impl_protocol_parser!宏。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 impl_protocol_parser! { pub enum L7ProtocolParser { // http have two version but one parser, can not place in macro param. // custom must in frist so can not place in macro DNS(DnsLog), SofaRPC(SofaRpcLog), MySQL(MysqlLog), Kafka(KafkaLog), Redis(RedisLog), + MongoDB(MongoDBLog), PostgreSQL(PostgresqlLog), Dubbo(DubboLog), FastCGI(FastCGILog), MQTT(MqttLog), // add protocol below } } 第二步的效果 通过perf_states统计记录QPS、耗时和异常情况
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 impl L7ProtocolParserInterface for MongoDBLog { fn parse_payload(&amp;mut self, payload: &amp;[u8], param: &amp;ParseParam) -&gt; Result&lt;L7ParseResult&gt; { let mut info = MongoDBInfo::default(); self.parse(payload, param.l4_protocol, param.direction, &amp;mut info)?; // 解码得到L7ProtocolInfo info.cal_rrt(param, None).map(|rrt| { info.rrt = rrt; + self.perf_stats.as_mut().map(|p| p.update_rrt(rrt)); // 耗时 }); } impl MongoDBLog { fn parse(&amp;mut self,payload:&amp;[u8],proto:IpProtocol,dir:PacketDirection,info:&amp;mut MongoDBInfo,) -&gt; Result&lt;bool&gt; { // 解码指令获取请求和响应等信息 if header.is_request() { + self.perf_stats.as_mut().map(|p: &amp;mut L7PerfStats| p.inc_req()); // 请求记录 } else { + self.perf_stats.as_mut().map(|p| p.inc_resp()); // 响应记录 } match info.op_code { _OP_REPLY if payload.len() &gt; _HEADER_SIZE =&gt; { let mut msg_body = MongoOpReply::default(); msg_body.decode(&amp;payload[_HEADER_SIZE..])?; if !msg_body.reply_ok { + self.perf_stats.as_mut().map(|p| p.inc_resp_err());// 异常记录 } } } } } 效果如图： 最后在server补充服务端的协议识别 以下两部分内容在代码文件server/libs/datatype/flow.go中 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 type L7Protocol uint8 const ( L7_PROTOCOL_UNKNOWN L7Protocol = 0 L7_PROTOCOL_OTHER L7Protocol = 1 L7_PROTOCOL_HTTP_1 L7Protocol = 20 L7_PROTOCOL_HTTP_2 L7Protocol = 21 L7_PROTOCOL_HTTP_1_TLS L7Protocol = 22 L7_PROTOCOL_HTTP_2_TLS L7Protocol = 23 L7_PROTOCOL_DUBBO L7Protocol = 40 L7_PROTOCOL_GRPC L7Protocol = 41 L7_PROTOCOL_SOFARPC L7Protocol = 43 L7_PROTOCOL_FASTCGI L7Protocol = 44 L7_PROTOCOL_MYSQL L7Protocol = 60 L7_PROTOCOL_POSTGRE L7Protocol = 61 L7_PROTOCOL_REDIS L7Protocol = 80 + L7_PROTOCOL_MONGODB L7Protocol = 81 L7_PROTOCOL_KAFKA L7Protocol = 100 L7_PROTOCOL_MQTT L7Protocol = 101 L7_PROTOCOL_DNS L7Protocol = 120 L7_PROTOCOL_CUSTOM L7Protocol = 127 ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 func (p L7Protocol) String() string { formatted := &#34;&#34; switch p { case L7_PROTOCOL_HTTP_1: formatted = &#34;HTTP&#34; case L7_PROTOCOL_DNS: formatted = &#34;DNS&#34; case L7_PROTOCOL_MYSQL: formatted = &#34;MySQL&#34; case L7_PROTOCOL_POSTGRE: formatted = &#34;PostgreSQL&#34; case L7_PROTOCOL_REDIS: formatted = &#34;Redis&#34; + case L7_PROTOCOL_MONGODB: + formatted = &#34;MongoDB&#34; case L7_PROTOCOL_DUBBO: formatted = &#34;Dubbo&#34; case L7_PROTOCOL_GRPC: formatted = &#34;gRPC&#34; case L7_PROTOCOL_CUSTOM: formatted = &#34;Custom&#34; case L7_PROTOCOL_OTHER: formatted = &#34;Others&#34; default: formatted = &#34;N/A&#34; } return formatted } server/querier/db_descriptions/clickhouse/tag/enum/l7_protocol
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # Value , DisplayName , Description 0 , N/A , 1 , Others , 20 , HTTP , 21 , HTTP2 , 22 , HTTP1_TLS , 23 , HTTP2_TLS , 40 , Dubbo , 41 , gRPC , 43 , SOFARPC , 44 , FastCGI , 60 , MySQL , 61 , PostgreSQL , 80 , Redis , +	81 , MongoDB , 100 , Kafka , 101 , MQTT , 120 , DNS , 127 , Custom , 到这里已经完成DeepFlow Agent的原生协议扩展了，参考《 # 完整指南：如何编译、打包和部署二次开发的 DeepFlow 》编译程序发布即可。
如果想快速实现一个协议采集解析，或者不熟悉Rust语言呢？我们还有一个选择，就是利用Wasm插件快速扩展协议解码。
利用Wasm插件扩展DeepFlow的协议采集 该案例是用Wasm扩展Kafka协议支持Topic的实践。 首先还是参考Kafka的官方文档对 Kafka协议 做一个简单的分析
Kafka协议分析 Kafka的Header和Data概览 Kafka的Fetch API Kafka的Produce API Kafka协议DeepFlow Agent原生解码 截止到v6.3.x版本，DeepFlow Agent对Kafka的原生解码如下图所示，还不支持Topic字段的解码， 且API的解码还没有版本号。 接下来的插件开发主要解决Topic字段的解码放在resource展示，同时把API的版本号也解析出来。
DeepFlow Agent的 Wasm 插件 参考官方插件文档《 wasm-plugin 》，需要注意两点：
Agent 通过遍历所有支持协议判断一个流的应用层协议，顺序是： HTTP -&gt; Wasm Hook -&gt; DNS -&gt; &hellip;
需要使用 Go 版本不低于 1.21 并且 tinygo 版本需要不低于 0.29
Wasm Go SDK 的框架 先对框架有一个大概的认识，如下代码所示，整个框架逻辑都在以下五个接口函数。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package main import &#34;github.com/deepflowio/deepflow-wasm-go-sdk/sdk&#34; // 定义结构，需要实现 sdk.Parser 接口 type plugin struct {} func (p plugin) HookIn() []sdk.HookBitmap {return []sdk.HookBitmap{}} // HookIn() 包含 HOOK_POINT_HTTP_REQ 时，http 请求解析完成返回之前会调用。 // HttpReqCtx 包含了 BaseCtx 和已经解析出来的一些 http 头部 func (p plugin) OnHttpReq(ctx *sdk.HttpReqCtx) sdk.Action { return sdk.HttpReqActionAbortWithResult(nil, trace, attr) } func (p plugin) OnHttpResp(ctx *sdk.HttpRespCtx) sdk.Action {return sdk.ActionNext()} func (p plugin) OnCheckPayload(baseCtx *sdk.ParseCtx) (uint8, string) {return 0, &#34;ownwasm&#34;} func (p plugin) OnParsePayload(baseCtx *sdk.ParseCtx) sdk.ParseAction { return sdk.ParseActionAbortWithL7Info([]*sdk.L7ProtocolInfo{}) } // main 需要注册解析器 func main() { sdk.SetParser(plugin{}) } Agent 会遍历所有插件调用对应的 Export 函数，但是遍历的行为可以通过返回值控制 返回值 说明 sdk.ActionNext() 停止当前插件，直接执行下一个插件 sdk.ActionAbort() 停止当前插件并且停止遍历 sdk.ActionAbortWithErr(err) 停止当前插件，打印错误日志并且停止遍历 sdk.HttpActionAbortWithResult() Agent 停止遍历并且提取相应返回结果 sdk.ParseActionAbortWithL7Info() Agent 停止遍历并且提取相应返回结果 ⚠️注意： 因为该案例不涉及HTTP协议的处理，所以OnHttpReq()和OnHttpResp()直接使用sdk.ActionNext() 跳过即可。 该案例也不会用到sdk.HttpActionAbortWithResult()。
HookBitmap的三个 hook 点 hook点 说明 HOOK_POINT_HTTP_REQ 表示 http 请求解析完成返回之前 HOOK_POINT_HTTP_RESP 表示 http 响应解析完成返回之前 HOOK_POINT_PAYLOAD_PARSE 表示协议的判断和解析 ⚠️注意： 因为该案例不涉及HTTP协议的处理，所以HOOK_POINT_HTTP_REQ和HOOK_POINT_HTTP_RESP在 该案例也不会用到。
插件代码指引 梳理后的Kafka协议的Wasm插件代码框架 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package main import &#34;github.com/deepflowio/deepflow-wasm-go-sdk/sdk&#34; // 定义结构，需要实现 sdk.Parser 接口 type kafkaParser struct {} func (p kafkaParser) HookIn() []sdk.HookBitmap { return []sdk.HookBitmap{sdk.HOOK_POINT_PAYLOAD_PARSE} } // 跳过HTTP协议处理 func (p kafkaParser) OnHttpReq(ctx *sdk.HttpReqCtx) sdk.Action {return sdk.ActionNext()} func (p kafkaParser) OnHttpResp(ctx *sdk.HttpRespCtx) sdk.Action {return sdk.ActionNext()} // 协议判断检查 func (p kafkaParser) OnCheckPayload(baseCtx *sdk.ParseCtx) (uint8, string) {return 100, &#34;kafka&#34;} // 协议解码 func (p kafkaParser) OnParsePayload(baseCtx *sdk.ParseCtx) sdk.ParseAction { return sdk.ParseActionAbortWithL7Info([]*sdk.L7ProtocolInfo{}) } // main 需要注册解析器 func main() {sdk.SetParser(plugin{})} 协议识别 ⚠️注意：以下代码注释
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 func (p kafkaParser) OnCheckPayload(ctx *sdk.ParseCtx) (uint8, string) { // 跳过UDP协议数据 if ctx.L4 != sdk.TCP { return 0, &#34;&#34; } // 如果环境有标准规范的端口约定，插件中指定端口会减少协议数据的遍历，优化解码时cpu等资源消耗 if ctx.DstPort &lt; 9092 || ctx.DstPort &gt; 9093 { return 0, &#34;&#34; } // 读取抓包数据 payload, err := ctx.GetPayload() if err != nil { sdk.Error(&#34;get payload fail: %v&#34;, err) return 0, &#34;&#34; } // 引用&#34;github.com/segmentio/kafka-go/protocol&#34;来解码 bl, err := protocol.ReadAll(protocol.NewBytes(payload)) if err != nil { sdk.Error(&#34;read payload fail: %v&#34;, err) return 0, &#34;&#34; } b, _ := decodeHeader(bl) if !b { return 0, &#34;&#34; } return WASM_KAFKA_PROTOCOL, &#34;kafka&#34; } 协议API解码
官方代码框架OnParsePayload()的逻辑如下 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 func (p plugin) OnParsePayload(baseCtx *sdk.ParseCtx) sdk.ParseAction { // ctx.L7 就是 OnCheckPayload 返回的协议号，可以先根据4层协议或协议号过滤。 if ctx.L4 != sdk.TCP {return sdk.ActionNext()} payload, err := ctx.GetPayload() if err != nil {return sdk.ActionAbortWithErr(err)} // the parse logic here // ... /* 关于 L7ProtocolInfo 结构： type L7ProtocolInfo struct { ReqLen *int // 请求长度 例如 http 的 content-length RespLen *int // 响应长度 例如 http 的 content-length RequestID *uint32 // 子流的id标识，例如 http2 的 stream id，dns 的 transaction id Req *Request Resp *Response Trace *Trace // 跟踪信息 Kv []KeyVal // 对应 attribute } type Request struct { ReqType string // 对应请求类型 Domain string // 对应请求域名 Resource string // 对应请求资源 Endpoint string // 对应 endpoint } type Response struct { Status RespStatus // 对应响应状态 Code *int32 // 对应响应码 Result string // 对应响应结果 Exception string // 对应响应异常 }*/ return sdk.ParseActionAbortWithL7Info([]*sdk.L7ProtocolInfo{}) } Topic字段解码的代码逻辑 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 func (p kafkaParser) OnParsePayload(ctx *sdk.ParseCtx) sdk.Action { // the parse logic here // ... // 解码 header base size : // req_len(int32) + api_key(int16) + api_ver(int16) + c_id(int32) + client_len(int16) // = 14 var header_offset = 14 + header.clientLen var topic_size int16 = 0 var topic_name = &#34;&#34; switch protocol.ApiKey(header.apikey) { case protocol.Produce: topic_size, topic_name = decodeProduce(header.apiversion, payload[header_offset:]) case protocol.Fetch: topic_size, topic_name = decodeFetch(header.apiversion, payload[header_offset:]) } if topic_size == 0 { return sdk.ActionNext() } req = &amp;sdk.Request{ ReqType: protocol.ApiKey(header.apikey).String() + &#34;_v&#34; + strconv.Itoa(int(header.apiversion)), Resource: topic_name, } return sdk.ParseActionAbortWithL7Info([]*sdk.L7ProtocolInfo{ { RequestID: &amp;id, ReqLen: &amp;length, Req: req, }, }) } 加载插件和效果展示 执行如下命令编译插件，通过CTL方式加载插件
1 2 3 ➜ deepflow-plugin git:(main) ✗ tinygo build -o build/topic.wasm -target wasi -panic=trap -scheduler=none -no-debug ./wasm/kafka/topic.go ➜ deepflow-plugin git:(main) ✗ deepflow-ctl plugin create --type wasm --image build/topic.wasm --name topic 准备好Agent的配置文件增加如下配置。注意，Agent可以加载多个 Wasm 插件。
1 2 3 4 5 6 7 ############ ## plugin ## ############ ## wasm plugin need to load in agent wasm-plugins: - mongo - topic 执行命令更新配置
1 ➜ deepflow-plugin git:(main) ✗ deepflow-ctl agent-group-config update -f g-d2d06af17e.yaml 当Agent日志出现如下图黄字体内容，即加载成功。 在Grafana上，可以看到原生的Kafka协议被覆盖，出现了几个变化：
Protocol 字段从Kafka 变成 Custom Request type字段的API多了版本号 Request resource字段出现了Topic信息 结语 最后对比一下两个协议扩展的方式，要注意⚠️的是： 两者都存在一个共性问题，就是每增加一个协议，识别协议解码的效率相对降低， 可以通过配置的方式减少需解码的协议数量
原生Rust扩展 优点：
运行时的资源占用比插件低 支持的功能比插件的丰富，且定制性更灵活 缺点：
在语言方面的开发难度比插件的大 相对插件开发而言，新增协议需要改动的地方较多，还涉及到Server的一小部分代码 Wasm插件扩展 优点：
用Golang开发相对Rust语言难度较低 可在运行时通过CLI方式加载 扩展性强 缺点：
Go 的标准库和第三方库有一定的限制，且调试难度大，导致插件异常较难排除 由于Wasm本身限制等问题，导致功能相对Rust原生开发较弱 资源增加，特别是内存方面。 附录 DeepFlow 协议开发文档 DeepFlow的Wasm 插件系统 使用 DeepFlow Wasm 插件实现业务可观测性 MongoDB协议文档 Kafka协议文档   ]]></content></entry><entry><title>VictoriaMetrics的指标流聚合能力应用</title><url>/posts/opentelemetry/stream-metrics-one/</url><categories><category>Prometheus</category><category>VictoriaMetrics</category></categories><tags><tag>Prometheus</tag><tag>VictoriaMetrics</tag></tags><content type="html"><![CDATA[  社区VM对指标流聚合能力分析与问题 VictoriaMetrics开源项目的原生能力 VictoriaMetrics项目中的流聚合能力是从1.86版本开始整合到vmagent的，具体可参考： https://github.com/VictoriaMetrics/VictoriaMetrics/issues/3460 从源码分析来看，流集合能力如图：
核心计算的代码在pushSample函数中有描述：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 func (as *totalAggrState) pushSample(inputKey, outputKey string, value float64) { currentTime := fasttime.UnixTimestamp() deleteDeadline := currentTime + as.intervalSecs + (as.intervalSecs &gt;&gt; 1) again: v, ok := as.m.Load(outputKey) if !ok { v = &amp;totalStateValue{ lastValues: make(map[string]*lastValueState), } vNew, loaded := as.m.LoadOrStore(outputKey, v) if loaded { v = vNew } } sv := v.(*totalStateValue) sv.mu.Lock() deleted := sv.deleted if !deleted { lv, ok := sv.lastValues[inputKey] if !ok { lv = &amp;lastValueState{} sv.lastValues[inputKey] = lv } d := value if ok &amp;&amp; lv.value &lt;= value { d = value - lv.value } if ok || currentTime &gt; as.ignoreInputDeadline { sv.total += d } lv.value = value lv.deleteDeadline = deleteDeadline sv.deleteDeadline = deleteDeadline } sv.mu.Unlock() if deleted { goto again } } 流聚合能力的一般运用分析 首先先看看流聚合后的时序图： 这时候，我们看看时序数据的理论形态 基于理论形态的理想流聚合形态 在实际状态下的流聚合形态 原生流聚合能力的日常问题 采集断点问题 在现实世界是更残酷的，某个时间断点是无可避免，原因很多，有网络上的、有被采集服务的性能问题等。 高精度的流聚合断点问题在大数计算情况下，影响是很极端的： 巨量数据的算力架构 流聚合没有历史数据细节的状态保存，因此性能极优，但是再优性能的服务也存在单点的极限值。在处理单点无法处理的数据量级情况下，分布式算力结构就会存在一系列问题要解决：
vmagent自带采集能力是否可用？ 在实际测试过程中，启动vmagent分片加副本采集能力结合实时流聚合，资源使用大幅增加，在量级极大的情况下频繁出现采集连续断点的问题，恶化了断点导致的计算结果差异问题。 架构图参考：
需计算的Sample数据分别给哪个算力点计算？ 多个算力点计算后的同维度指标集因同维度同时间窗口但不同结果值导致后到值丢弃的问题如何解决？（触发乱序指标处理逻辑） 分布式计算的资源均衡问题？ 插入任务id解决计算点同维度分辨问题后再次引入新维度如何解决？ 分布式流聚合的网关设计与实现 上述章节分析了目前业界方案结合实际场景遇到的问题分析后，这一节会有针对性的对问题一一解决。 通过源码分析有两个关键部分：
时间窗口的范围： 1 2 3 //窗口的范围是间隔设置加上间隔向右位移1位 currentTime := fasttime.UnixTimestamp() deleteDeadline := currentTime + as.intervalSecs + (as.intervalSecs &gt;&gt; 1) 计算窗口的逻辑： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 // 从缓存读取需聚合的指标 v, ok := as.m.Load(outputKey) if !ok { v = &amp;totalStateValue{ lastValues: make(map[string]*lastValueState), } vNew, loaded := as.m.LoadOrStore(outputKey, v) if loaded { v = vNew } } sv := v.(*totalStateValue) sv.mu.Lock() deleted := sv.deleted if !deleted { // 从聚合后指标的缓存里面查找流入的时间线的记录值 lv, ok := sv.lastValues[inputKey] if !ok { // 如果没有记录值，则取原始值作为记录值 lv = &amp;lastValueState{} sv.lastValues[inputKey] = lv } d := value if ok &amp;&amp; lv.value &lt;= value { // 如果有记录值，则取新值与记录值的差值作为聚合后指标的追加值 d = value - lv.value } if ok || currentTime &gt; as.ignoreInputDeadline { sv.total += d } lv.value = value lv.deleteDeadline = deleteDeadline sv.deleteDeadline = deleteDeadline } 从源码解读，流聚合逻辑只对时间窗口做了简易的周期判断，在流入指标因各种原因导致延迟抵达的问题导致计算值被放大没有太多逻辑处理。 这时候，我们需要一个前置模块来解决一些问题，也因vmgateway是企业组件，所以我们开发了一个属于自己的分布式流聚合的网关vm-receive-route。
分布式流聚合网关处理的问题 异步 大部分的 remote write项目 都是同步转发的。比如 prometheus-kafka-adapter 就是等kafka完成数据生产逻辑后才完成整个写流程，从而处理下一批remote write的数据。 但是流计算对数据处理是有窗口限制的，如果用同步逻辑阻塞在这里，就会影响性能，导致后续的时间sample会延迟，延迟错过了流计算的时间窗口的话，就会出现计算偏差。所以这里适合异步转发。
时间窗口的过滤 因流聚合逻辑已经对时间线的差值做了前后大小的判断，这里就不需要引进 out-of-order算法 网关这里只需要配合流聚合逻辑的时间窗口做sample过滤丢弃则可。 主要解决因网络导致Prometheus重试发送大量积压旧sample影响实时值的计算结果，也解决了Prometheus重试大量积压sample引发的资源性能问题。
维度控制 由于流聚合组件会给每条聚合后时间线插入一个节点ID来区分label。但是随着节点的横向扩容，这个label的维度也会随之增加。这里需要有一种控制维度的能力，并且能同时把时间线按维度ID来给不同的节点处理。后面我们设计了一个双重hashmod调度分配任务算法来解决这类问题。 把标记taskid的能力前置到网关，这样就可以无视整个结构的横向扩容的节点数对任务ID维度的影响 双重hashmod调度分配任务 略
后端异常服务转移 略
程序流程逻辑图 线上环境架构图 Record Rule维度任务生成器 流聚合计算是一种实时处理和分析大量数据流的技术。其主要目的是从高速、连续不断的数据流中提取有价值的信息，例如：计算平均值、求和、最大值、最小值等。流聚合计算通常会在内存中进行，以保持较低的延迟和高吞吐量。
流聚合计算的实现通常包含以下几个关键部分：
数据源和数据接收器：设定和监控数据流，如：日志、网络数据包、传感器数据等，将数据流分为多个小批次。 窗口操作：数据流会被分成一系列固定或滑动窗口。每个窗口内的数据会进行预先定义的聚合操作。 聚合函数：对窗口内的数据进行各种操作,例如：计数、求和、均值、最大/最小值等。 输出：将聚合结果输出或存储，以备进一步处理或实时数据可视化。 在指标流聚合中，该能力是对单一指标做高效的降维计算，但是在现实中要描述复杂场景是需要对多指标来结合函数计算的。
流聚合可以高效解决以下聚合过滤req_path的字段
聚合前： 1 2 3 4 5 6 7 a_http_req_total{zone=&#34;bj&#34;,src_svr=&#34;192.168.1.2&#34;,src_port=&#34;30021&#34;,dis_svr=&#34;192.168.2.3&#34;,dis_port=&#34;8080&#34;,code=&#34;202&#34;,req_path=&#34;/xxxx/yyyy?abc=exg&#34;} a_http_req_total{zone=&#34;bj&#34;,src_svr=&#34;192.168.1.2&#34;,src_port=&#34;30023&#34;,dis_svr=&#34;192.168.2.3&#34;,dis_port=&#34;8080&#34;,code=&#34;202&#34;,req_path=&#34;/xxxx/yyyy?abc=sdf&#34;} a_http_req_total{zone=&#34;bj&#34;,src_svr=&#34;192.168.1.2&#34;,src_port=&#34;10021&#34;,dis_svr=&#34;192.168.2.3&#34;,dis_port=&#34;8080&#34;,code=&#34;202&#34;,req_path=&#34;/xxxx/yyyy?abc=fasdfa&#34;} a_http_req_total{zone=&#34;bj&#34;,src_svr=&#34;192.168.1.2&#34;,src_port=&#34;20210&#34;,dis_svr=&#34;192.168.2.3&#34;,dis_port=&#34;8080&#34;,code=&#34;202&#34;,req_path=&#34;/xxxx/yyyy?abc=asdfe&#34;} a_http_req_total{zone=&#34;bj&#34;,src_svr=&#34;192.168.1.2&#34;,src_port=&#34;20211&#34;,dis_svr=&#34;192.168.2.3&#34;,dis_port=&#34;8080&#34;,code=&#34;202&#34;,req_path=&#34;/xxxx/yyyy?abc=sfadsf&#34;} a_http_req_total{zone=&#34;bj&#34;,src_svr=&#34;192.168.1.2&#34;,src_port=&#34;21210&#34;,dis_svr=&#34;192.168.2.3&#34;,dis_port=&#34;8080&#34;,code=&#34;500&#34;,req_path=&#34;/xxxx/yyyy?abc=caresaf&#34;} a_http_req_total{zone=&#34;bj&#34;,src_svr=&#34;192.168.1.2&#34;,src_port=&#34;30121&#34;,dis_svr=&#34;192.168.2.3&#34;,dis_port=&#34;8080&#34;,code=&#34;400&#34;,req_path=&#34;/xxxx/yyyy?abc=werads&#34;} 聚合后： 1 2 3 agg_a_http_req_total{zone=&#34;bj&#34;,src_svr=&#34;192.168.1.2&#34;,dis_svr=&#34;192.168.2.3&#34;,dis_port=&#34;8080&#34;,code=&#34;202&#34;} agg_a_http_req_total{zone=&#34;bj&#34;,src_svr=&#34;192.168.1.2&#34;,dis_svr=&#34;192.168.2.3&#34;,dis_port=&#34;8080&#34;,code=&#34;500&#34;} agg_a_http_req_total{zone=&#34;bj&#34;,src_svr=&#34;192.168.1.2&#34;,dis_svr=&#34;192.168.2.3&#34;,dis_port=&#34;8080&#34;,code=&#34;400&#34;} 但是我们最终要做展示的是某个目标地址的成功率：
1 2 3 4 5 6 7 8 9 sum by (dis_svr) ( rate(a_http_req_total{code=~&#34;2.*&#34;}[5m]) ) / sum by (dis_svr) ( rate(a_http_req_total{}[5m]) ) 我们可以利用Prometheus的Record Rule来直接算聚合场景指标。
1 2 3 4 5 6 7 8 groups: - name: a_http_req_total:sum:rate:5m rules: - expr: sum by (src_svr,dis_svr,code) ( rate(a_http_req_total{}[5m]) ) record: a_http_req_total:sum:rate:5m 但是Record Rule会把指标a_http_req_total的所有维度数据加载到内存，如果维度达到临界值就会触发内存OOM。即使没有达到临界值，该计算量也会随着维度增加以致计算结果点被延迟。 在实际生产环境中，istio_request_total的qps数据会延迟20分钟之久。 在结合流聚合计算把维度降低，使时间线从千万级别降低到万级别，也只是从20分钟的延迟降低到1-2分钟。 流聚合后的Record Rule的配置：
1 2 3 4 5 6 7 8 groups: - name: agg_a_http_req_total:sum:rate:5m rules: - expr: sum by (src_svr,dis_svr,code) ( rate(agg_a_http_req_total{}[5m]) ) record: agg_a_http_req_total:sum:rate:5m 通过分析Rule模块的源码，我们可以做更细化的配置能力：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 groups: - name: agg_a_http_req_total:sum:rate:5m-2xx rules: - expr: sum by (src_svr,dis_svr,code) ( rate(agg_a_http_req_total{code=~&#34;2.**&#34;}[5m]) ) record: agg_a_http_req_total:sum:rate:5m - name: agg_a_http_req_total:sum:rate:5m-4xx rules: - expr: sum by (src_svr,dis_svr,code) ( rate(agg_a_http_req_total{code=~&#34;4.**&#34;}[5m]) ) record: agg_a_http_req_total:sum:rate:5m - name: agg_a_http_req_total:sum:rate:5m-5xx rules: - expr: sum by (src_svr,dis_svr,code) ( rate(agg_a_http_req_total{code=~&#34;5.**&#34;}[5m]) ) record: agg_a_http_req_total:sum:rate:5m 这样我们就可以通过对某个维度标签拆分的查询，以达到生成同样的新指标并发处理能力。
问题是，生产的维度标签大多数是动态变化的，我们怎么去动态生成这种按维度标签拆分的查询来实现并发Record Rule呢？我们需要一个对标签元数据的管理系统来对标签维度元数据进行跟踪和管理。 这时候我们实现了一个小型的元数据watch模块和rule build模块来解决该问题。 该组件ruler-handle-process的配置是这样子的：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 recode_rules: - interval: 5m recode_to: istio_requests_total:sum:rate:5m metric_name: istio_requests_total aggr_type: sum vector_type: rate vector_range: 5m group_by_and_filter: - source_workload - destination_workload - cluster - namespace group_by: - response_code - namespace - source_workload_namespace - destination_workload_namespace - destination_service_name - cluster - reporter filter_by: cluster: &#34;k8s-hw-bj-xxxxxx&#34; with_out: source_workload: &#34;ingressgateway-workflows&#34; ruler-handle-process就会watch指标名&quot;istio_requests_total&quot;下的response_code、namespace、source_workload_namespace、destination_workload_namespace、destination_service_name、cluster、reporter的维度组合来生成一堆Record Rule规则。 结合Rule组件来实现并发计算，我们就可以把计算延迟缩短到秒级完成。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 groups: - name: istio_requests_total:sum:rate:5m-7218756fe8a0bc327e818812cefb02f7 rules: - expr: sum by (request_protocol, grpc_response_status, response_code, svr_response_code, namespace, source_workload_namespace, destination_workload_namespace, destination_service_name, cluster, reporter, source_workload, destination_workload, cluster, namespace) (rate(istio_requests_total{cluster=&#34;k8s-hw-bj-1-prod&#34;,destination_workload=&#34;skyaxe-778-flink&#34;,namespace=&#34;istio-ingress&#34;,source_workload=&#34;ingressgateway-streaming&#34;}[5m])) record: istio_requests_total:sum:rate:5m - name: istio_requests_total:sum:rate:5m-8e30244048f8d5519a6332f309578ed4 rules: - expr: sum by (request_protocol, grpc_response_status, response_code, svr_response_code, namespace, source_workload_namespace, destination_workload_namespace, destination_service_name, cluster, reporter, source_workload, destination_workload, cluster, namespace) (rate(istio_requests_total{cluster=&#34;k8s-hw-bj-1-prod&#34;,destination_workload=&#34;t-bean-portal&#34;,namespace=&#34;coin&#34;,source_workload=&#34;unknown&#34;}[5m])) record: istio_requests_total:sum:rate:5m - name: istio_requests_total:sum:rate:5m-ea2d81ce1c35a7ba5a72b9e23fe7faf6 rules: - expr: sum by (request_protocol, grpc_response_status, response_code, svr_response_code, namespace, source_workload_namespace, destination_workload_namespace, destination_service_name, cluster, reporter, source_workload, destination_workload, cluster, namespace) (rate(istio_requests_total{cluster=&#34;k8s-hw-bj-1-prod&#34;,destination_workload=&#34;wefly-ad-report&#34;,namespace=&#34;wf&#34;,source_workload=&#34;wefly-app-packages&#34;}[5m])) record: istio_requests_total:sum:rate:5m 指标流聚合在监控平台的架构组合 在我们利用社区开源程序和我们的自研组件，在不同采集量场景下可以做不同的组合来解决不同量级的高维度数据。
万级别单一指标的流聚合 万级别多指标的计算聚合 百万级别以上的单一指标流聚合 百万级别以上的指标对场景的计算聚合   ]]></content></entry><entry><title>eBPF系列之：Pixie浅剖析</title><url>/posts/ebpf/pixie-try/</url><categories><category>eBPF</category></categories><tags><tag>eBPF</tag></tags><content type="html">  部署过程和指令参考： pixie install Pixie平台主要由以下组件组成： Pixie Edge Module 边缘模块(PEM): Pixie&amp;amp;rsquo;s agent, installed per node. PEMs use eBPF to collect data, which is stored locally on the node. Pixie的代理，安装在每个节点上。PEM使用eBPF收集数据，这些数据存储在节点本地。
Vizier: Pixie’s collector, installed per cluster. Responsible for query execution and managing PEMs. Pixie的收集器，安装在每个集群上。负责查询执行和管理PEM。
Pixie Cloud: Used for user management, authentication, and data proxying. Can be hosted or self-hosted. 用于用户管理、身份验证和数据代理。可以托管或自托管。
Pixie CLI: Used to deploy Pixie. Can also be used to run queries and manage resources like API keys. 用于部署Pixie。还可用于运行查询和管理API密钥等资源。
Pixie Client API: Used for programmatic access to Pixie (e.g. integrations, Slackbots, and custom user logic requiring Pixie data as an input) 用于对Pixie进行编程访问（例如，集成、Slackbots和需要Pixie数据作为输入的自定义用户逻辑）
本地部署涉及的组件和步骤： 初始化 日常运行时 Pixie自动收集以下数据：
Protocol traces: Full-body messages between the pods of your applications. Tracing currently supports the following list of protocols . For …  </content></entry><entry><title>闲聊一下CPU时序和现代操作系统二三事</title><url>/posts/opentelemetry/talk-about-cpu-timer/</url><categories><category>Linux</category><category>CPU</category></categories><tags><tag>Linux</tag></tags><content type="html"><![CDATA[  时分系统和Linux 首先我们补习一下时分系统，时分系统是一个非常重要的操作系统概念,它最大限度地提高了运算机的利用率,是实现多道程序并发执行的重要手段。 我们日常工作用到的Linux系统 内核也采用了时分系统的思想,主要体现在以下几个方面:
时间片: Linux 使用时间片机制对 CPU 进行时间分割,每个进程只能执行一个时间片的时间,然后交出 CPU 给其他进程运行。这实现了 CPU 时间的共享与公平分配。
上下文切换: 当时间片用完或进程主动放弃 CPU 时,会进行上下文切换,保存当前进程上下文并恢复下一个进程上下文。这使得 CPU 可以高效地在不同进程间切换。
进程调度: Linux 使用 CFS 调度器根据每个进程的时间片选择最适合运行的进程,这是时分系统思想的体现。不同的调度策略可以实现不同的时分效果。
中断机制: Linux 使用中断机制实现对时间的管理与调度。时钟中断可以在时间片用完时通知内核进行上下文切换与调度。这为时分系统提供了动力基础。
时钟事件: Linux 基于时分系统管理各种时间事件,如定时器、睡眠唤醒等。这需要内核根据时钟中断来进行管理与调度。
除此之外,时分系统的思想在 Linux 中还体现在:
多道程序设计 Linux 支持多道程序并发运行,这也依赖于时分系统实现的 CPU 时间共享机制。 实时性 通过设置实时调度策略和对中断处理的优化,Linux 可以提供较好的实时响应性能。这也需要时分系统的支持。 睡眠唤醒 进程可以主动睡眠释放 CPU,这需要时分系统在其唤醒后重新调度其 CPU 时间。 同步机制 Linux 提供多种同步机制,这都需要时分系统来实现进程之间的协调与调度。 时分系统是 Linux 实现多道程序、并发执行、实时响应、时间管理等功能的基础。它使 Linux 能够充分利用 CPU 资源,实现高效率与公平的调度。时分系统的思想贯穿 Linux 内核的方方面面,是理解 Linux 调度与实现并发执行的重要概念。
聊一下Linux的时序 接下来我们需要提前了解几个概念：
Some Words Jiffies 有更多兴趣的可以看看《 内核时钟问题 》
jiffies是一个非常重要的Linux内核变量,它代表了自系统启动以来的时间戳,以时钟中断的个数来表示。它有以下特点:
jiffies以时钟中断的个数来衡量时间,所以它的精度由时钟中断频率决定。一般的1000HZ时钟中断,jiffies的精度为1ms。 jiffies是一个无符号的长整型数值,会随着时钟中断不断累加。所以它的取值范围决定了Linux可以持续运行的最大时间。 jiffies的值在溢出后会重新从0开始累加。所以它只能用于衡量从某个时刻起的较短时间,不能直接用于表示系统的绝对时间。 内核中的很多时间相关参数都使用jiffies作为单位,如时间片的大小、时钟中断的间隔等。这使得Linux可以根据不同的时钟源进行 Migration。 jiffies可以用于比较两个时间戳之间的时间差,判断某个事件是否超时等。但在比较绝对时间时要特别注意jiffies的溢出问题。 可以通过jiffies的变化速度来粗略判断Linux内核的负载情况。jiffies变化越快,说明时钟中断越频繁,系统负载可能越重。 在用户空间,可以通过/proc/uptime文件来获取以秒为单位的系统启动时间与当前jiffies值。这可以用于计算系统的绝对时间等。 所以,jiffies作为Linux内核中的时间戳变量,具有以下重要意义:
它使Linux的时间单位由具体的时钟源独立,可以根据不同的时钟进行Migration。 它用于衡量较短的时间区间,判断超时等,但由于可能的溢出,不适用于表示绝对时间。 它的变化情况可以反映系统的负载情况,用于粗略判断系统性能。 通过它可以在内核与用户空间translating不同时间单位,如HZ与秒。 许多内核定时与时序相关的参数都基于jiffies,所以它是Linux时间管理的基础。 理解jiffies的含义与作用,可以帮助我们更深入理解Linux内核的时间管理机制。它使Linux的时间单位由硬件时钟源独立,是Linux灵活管理时间的基石。
CPU时间片 CPU时间片是操作系统为实现CPU调度而引入的一种机制。它的主要作用是:
实现CPU资源的公平共享,通过定期中断当前运行进程,让其他进程也有机会运行,避免优先级高的进程独占CPU。 避免任何一个进程长时间占用CPU,影响其他进程运行与系统的响应速度。 为CPU调度器提供时机,定期重新评估进程优先级,选择最适宜运行的进程。 CPU时间片的原理是:
操作系统根据时钟中断来对CPU的使用进行隔离与限制。当时间片用完时,会暂停当前运行进程,让CPU调度器选择其他进程运行。 CFS调度器会根据进程的优先级与其他因素为每个进程分配一个时间片,决定其可以运行的时间。 进程运行时会消耗其时间片,当时间片用完时会被调度出CPU,腾出时间让其他进程运行。 进程如果在时间片用完前主动放弃CPU(如IO阻塞),其剩余时间片会被保存,在下次获得CPU时继续使用。 实时进程可以设置固定的时间片,不受CFS调度器影响,以保证其实时响应需求。 CPU时间片的大小(时钟中断频率)直接影响着调度的频率与公平性。时间片较小,可以增强公平性与响应速度;但也会增加上下文切换开销。时间片的设置需要平衡公平性与效率。
在Linux内核中,时钟中断频率为1000HZ,时间片默认为1ms。CFS调度器会根据各进程的漂移值动态调整时间片大小,但不会超过默认最大时间片。这可以很好地平衡调度的公平性与开销。
CPU队列 CPU队列是Linux内核用于管理可运行进程( TASK_RUNNING状态)的一种数据结构。它主要有以下作用:
临时保存可运行但未被当前CPU选择的进程,等待下次调度。 根据进程的优先级、调度策略对进程进行排序,为CPU调度提供候选进程。 实现公平的CPU资源共享,防止优先级高的进程独占CPU。 Linux内核的CPU队列主要有以下几种:
运行队列(runqueue):每CPU一个,保存正在该CPU上运行或准备运行的进程。CFS调度器直接从该队列中选择进程调度运行。 备选队列(backup queue):全局只有一个,保存从其他CPU上被推出的进程,等待重新调度。主要防止优先级高的进程被starvation。 过期队列(expired queue):全局只有一个,保存时间片用完但优先级较高未立即调度出CPU的进程。等待下次调度考虑。 唤醒队列(wakeup queue):全局只有一个,保存从睡眠状态被唤醒的进程,等待下次调度。 这些CPU队列间的数据流转如下:
新创建的进程 &ndash;&gt; 唤醒队列 &ndash;&gt; 备选队列 &ndash;&gt; 过期队列 &ndash;&gt; 运行队列
处于RUNNING状态的进程会被添加到各自CPU的运行队列等待调度运行;如果被调度出CPU会进入备选队列或过期队列;从睡眠唤醒会进入唤醒队列。这些队列围绕 RUNNABLE和RUNNING两种状态对进程进行管理与排序。
CFS调度器会从运行队列和备选队列选择进程进行调度。过期队列和唤醒队列的进程也会在适当情况下被提前调度运行。这些队列的使用与进程之间的流转,确保了每个CPU资源可以充分并公平地被需要使用的进程利用,实现了Linux的时间共享调度策略。
SO？ 在Linux内核中,CPU时间片用于实现CPU调度中的时间共享,它的处理逻辑如下:
内核定期根据时钟中断来隔离进程或线程与CPU的执行,这就是CPU上下文切换,目的是为了重新选择其他进程或线程运行。 时钟中断频率决定了时间片的大小,时钟越快,时间片越小,CPU调度越频繁。早期通过PIT提供100HZ(10ms)的时钟中断,现代内核主要使用HPET提供的1000HZ(1ms)中断。 时间片的分配由CFS调度器决定,原则上每个进程获得的时间片大小应该与它的优先级和漂移值成正比。CFS会实时计算每个进程的vruntime来判断其获得的时间片。 内核通过托管进程上下文来记录进程运行的时间片使用情况,包括:时间片大小、已经使用的时间片、是否在运行等,这些信息保存在task_struct结构体中。 当进程获得CPU执行资源时,会从time_slice中减去使用的时间片,如果time_slice用完,则意味着时间片用完,应进行调度并重新选择其他进程运行。 如果在时间片用完之前,进程主动放弃CPU(如睡眠、IO等),则剩余的时间片会保留,在下次获得CPU执行时继续使用。但切换超过一定次数后,原有时间片会作废,从新分配。 内核会根据时钟中断周期不断检查正在运行的进程时间片使用情况,一旦时间片用完,就会将该进程置为可调度状态,并选择其他进程运行。 针对实时进程,内核可以设置静态的时间片,让其不受CFS调度器的管理,获得定期的CPU执行时间。这可以满足实时进程的需求。 所以,在Linux内核的CPU调度中,时间片起着非常重要的作用。它可以实现公平的CPU共享,满足不同进程的调度需求。内核通过时钟中断、CFS调度器和进程上下文来实现时间片的分配、管理与使用检查,以控制每个CPU运算周期中各个进程获得的执行时间,实现CPU资源的分配与调度。
那时钟中断频率和时间片有什么关系和区别？ 时钟中断频率和时间片是两个相关但不同的概念:
时钟中断频率决定了时钟中断的次数,即CPU上下文切换的频率。时钟中断越频繁,上下文切换越频繁,时间片就越小。 时间片决定了每个进程在获得CPU时间后可以占用CPU的最大时间长度。时间片的大小由操作系统根据时钟中断频率与调度策略来确定。 时钟中断是一种事件,用于通知操作系统隔离当前运行的进程,选择其他进程运行。它的频率反映了这个隔离动作的次数。 时间片是一种资源分配机制,它决定了每个进程获得CPU时间后可以独占使用CPU的时间长短。 它们的关系是:
时钟中断频率越高,时间片就越小。比如100HZ对应10ms时间片,1000HZ对应1ms时间片。 时间片的大小限制了一个进程可以独占CPU运行的最长时间。时钟中断用于在时间片用完时强制隔离当前进程,让其他进程运行。 时钟中断必须大于等于时间片大小。如果时钟中断频率为10HZ,但时间片为5ms,将是不合理的,这会导致定时器在时间片内无法生效。 较小的时间片可以增强调度的公平性与响应速度,但会增加上下文切换开销。时钟中断频率与时间片的设置需要在这两个方面进行权衡。 所以,总结来说:
时钟中断频率决定了CPU上下文切换的频率,影响操作系统的调度频率。 时间片决定了每个进程CPU占用时间的大小,影响调度的公平性与进程等待时间。 时钟中断频率越高,时间片越小;但也增加上下文切换开销。 它们需要根据系统需求进行权衡,设置合适的参数。 正确理解时钟中断与时间片的关系与区别,对学习操作系统的调度机制非常重要。时钟中断提供了调度的动力,时间片实现了调度的公平策略。两者相互配合,才能完成操作系统高效而合理的CPU调度。 所以,总的来说,时钟中断频率决定了调度的节奏,时间片决定了每个进程的时间分配。它们共同构成操作系统CPU调度的基本机制。
补习了这些概念有啥用？ 我们开发出来的程序和产品跑在现代操作系统上，也包括Kubernetes等，知名的大佬都在研究时间的处理问题，有兴趣可以点击下面的链接看看： https://github.com/kubernetes/kubernetes/pull/111520 https://github.com/zalando-incubator/kubernetes-on-aws/pull/923 甚至包括知名理论《 排队论 》
排队论 排队论是运筹学的一个重要分支,主要研究的是排队系统的性能分析与优化。它通过建立数学模型来分析客户的到达模式、服务模式、排队discipline等因素对系统性能的影响,帮助我们理解和优化复杂的排队系统。 排队论可以很好地用来描述和分析CPU的时序问题。我们可以将CPU看作一个服务器,任务或进程作为客户,建立数学模型来分析不同调度策略对CPU性能的影响。 具体来说,我们可以这样建模:
客户:CPU上的任务或进程,它们会不断地到达与等待CPU服务。这些任务的到达模式可以看作是随机的。 服务器:CPU内核,它按照一定的规则为任务提供计算服务。CPU的服务时间也可以看作是一个随机变量。 排队区:就绪队列(ready queue),保存已就绪等待运行的任务。不同的调度规则对应不同的排队规则。 服务机制:CPU调度器,它从就绪队列中选择任务并调度到CPU上运行。不同的调度算法对应不同的服务机制。 基于该模型,我们可以分析不同调度策略对CPU性能的影响:
FCFS:就绪队列相当于FIFO,会对短任务不公平,长任务的响应会很长。 SJF:可以优化平均响应时间,但可能导致长任务的starvation。 轮转法:间接限制每个任务的CPU时间,可以提高公平性但可能会降低CPU利用率。 优先级:为高优先级任务提供更快服务,可以提高效率,但也可能出现priority inversion等问题。 反馈队列:根据任务的CPU使用情况动态调整其优先级,在公平性与效率间达到平衡。 增加CPU数量:可以提高系统吞吐量,但也增加硬件成本与管理难度。 亲和性:将任务与特定CPU绑定,可以提高缓存利用率与性能,需要权衡任务移动开销。 所以,我们可以看到,CPU调度中的许多问题如公平性、吞吐量、响应性、优先级等,都可以借助排队论的模型与分析方法来研究。通过调整服务模式、排队规则与 CPU 数量等参数,可以实现不同的调度策略,优化 CPU 性能。
排队论为我们理解和分析复杂的 CPU 调度机制提供了非常有用的工具和思路。它可以将调度问题数学化与模型化,帮助我们从更高的角度去思考与优化问题。所以,排队论是我们研究操作系统与学习 CPU 调度机制的重要基础理论之一
提外话也聊一下 观测CPU截流 CPU截流的原理是控制进程对CPU的访问,以保证系统的稳定性和公平性。它的主要思想是:当CPU超过某个利用阈值时,限制进程对CPU的访问,从而防止CPU过度占用。
CPU截流通常用于以下场景: 防止CPU过载。当系统CPU利用率过高时,通过CPU截流可以限制个别进程的CPU使用,避免CPU过载导致系统崩溃或响应缓慢。 保证服务质量。可以通过CPU截流来保证关键业务进程获取足够的CPU资源,避免被其他进程挤占。这样可以为关键业务提供稳定的服务质量。 防止进程CPU starvation。通过CPU截流可以避免个别进程长期无法获取CPU时间片的情况,保证每一个进程都有机会运行。 CPU截流通常有两种主要方式: 时间片截流。限制进程在每个时钟中断周期内可以使用的CPU时间片。例如可以限制为原来的80%。 IO速率限制。限制进程的IO吞吐速率,间接限制其CPU使用。因为CPU使用通常伴随着IO操作,限制IO可以减少CPU占用。 在Linux系统中,可以使用ulimit、cpulimit等工具来设置进程的CPU截流。另外,cgroups也提供了CPU限制功能,可以更精细地控制容器/进程的CPU使用。
CPU截流是一个非常有用的技术,它可以帮助系统管理员更好地管理CPU资源,提供更加稳定可靠的服务。但如果使用不当,也会影响系统和业务的性能,所以需要慎重设置各个进程的CPU限制。
CPU截流的计算逻辑主要涉及两个方面: CPU利用率计算。需要实时计算系统和各个进程的CPU利用率,作为CPU截流的判断标准。
CPU利用率的计算公式为:CPU使用时间/测量间隔时间。其中,CPU使用时间可以从/proc/stat中获取,测量间隔时间一般选取1秒。
系统CPU利用率 = (user + nice + system + idle) / 总时间 进程CPU利用率 = 进程使用CPU时间 / 总时间 CPU截流判断与执行。需要根据CPU利用率判断是否需要执行CPU截流,如果需要则计算每个进程的CPU限制并执行限制。
判断逻辑可以为:
如果系统CPU利用率 &gt; 阈值(例如80%)则触发系统级CPU截流 如果关键进程CPU利用率 &lt; 最小阈值(例如50%)则触发针对该进程的CPU截流 如果普通进程CPU利用率 &gt; 最大阈值(例如20%)则触发针对该进程的CPU截流 CPU限制的计算可以基于进程原有的CPU份额来计算,例如:
系统级别:每个进程CPU限制 = 进程原有CPU份额 * 系统阈值(例如80%) 进程级别:该进程CPU限制 = 进程原有CPU份额 * 进程阈值(例如50%或20%) 手动设置某些关键进程的CPU限制,其余进程按比例分配 Prometheus和CPU截流的小故事： 一般主机场景 Prometheus可以很方便地实现CPU截流监控与预警。主要可以通过以下几个方面:
CPU利用率指标:
计算系统总体CPU利用率:rate(node_cpu_seconds_total{mode=&ldquo;system&rdquo;}[1m]) / 60 计算每个进程的CPU利用率:rate(process_cpu_seconds_total{name=&ldquo;过程名&rdquo;}[1m]) / 60 根据CPU利用率判断是否超过阈值,如果超过则触发CPU截流或预警:
1 2 alert: CPUUtilizationTooHigh expr: rate(node_cpu_seconds_total{mode=&#34;system&#34;}[1m]) / 60 &gt; 0.8 1 2 alert: ProcessCPUOveruse expr: rate(process_cpu_seconds_total{name=&#34;过程名&#34;}[1m]) / 60 &gt; 0.5 如果触发CPU截流,则需要计算每个进程的CPU限制并设置:
进程CPU限制 = 进程原有CPU使用量 * (1 - 系统超出阈值的cpu使用比例)
举例:
系统CPU利用率阈值:80% 当前系统CPU利用率:90% 某进程原有CPU使用量:20% 则:进程CPU限制 = 20% * (1 - (90% - 80%) / 90%) = 10%
也就是该进程的CPU利用率限制会从20%降低到10%,实现对其CPU使用量的限制,达到CPU截流的目的。
根据CPU限制值,调用cgroup或其他机制设置进程的CPU限额:
1 cgroup_cpu_limit{process_name=&#34;进程名&#34;,cpu_limit=&#34;10%&#34;} 此时Prometheus通过步骤1计算cpu利用率,步骤2判断是否超阈值需要CPU截流,步骤3计算每个进程的CPU限制,步骤4设置cgroup对进程的CPU限额来完成整个CPU截流的 workflow。
Kubernetes集群 在Kubernetes中,可以通过Prometheus监控Pod的CPU利用率并进行CPU截流。主要步骤如下:
监控Pod的CPU利用率指标:
1 rate(container_cpu_usage_seconds_total{pod=~&#34;pod_name&#34;, container=~&#34;container_name&#34;}[1m]) 设置CPU利用率阈值,超过阈值触发报警(表示需要对该Pod进行CPU截流):
1 2 alert: PodCPUOveruse expr: rate(container_cpu_usage_seconds_total{pod=~&#34;pod_name&#34;, container=~&#34;container_name&#34;}[1m]) &gt; 0.8 计算Pod的CPU限制值:
Pod CPU限制 = 总CPU限额 * (1 - 超出阈值的CPU使用比例)
例如,Pod总CPU限额为2个CPU,当前CPU利用率为90%,阈值为80%。则:
Pod CPU限制 = 2 * (1 - (90% - 80%) / 90%) = 1 个CPU
设置Pod的CPU限额,有两种主要方式:
1 kubectl patch pod pod-name -p &#39;{&#34;spec&#34;:{&#34;containers&#34;:[{&#34;name&#34;:&#34;container-name&#34;,&#34;resources&#34;:{&#34;limits&#34;:{&#34;cpu&#34;: &#34;1&#34;}}}]} }&#39;   ]]></content></entry><entry><title>监控系统企业架构演进史-拨测监控</title><url>/posts/opentelemetry/prometheus-evolution-history-three/</url><categories/><tags/><content type="html">  前情概述： 在《监控系统企业架构演进史-跨地域混合云》中，监控系统已经逐步成熟且企业化发展。 这一章节简单讲述一下期间的拨测能力搭建，以下是这套系统的发展史，在监控平台搭建的过程中，内部监控采集还不足以满足企业业务需求，在计划发展apm之前，异地拨测的黑匣子监控也纳入了该系统的一个子功能。
拨测监控架构的实现 系统搭建⾯临需解决的问题：
⻓期以来企业在公⽹监控，乃⾄⽤⼾侧最后⼀公⾥的监控都存在空洞，导致⽤⼾侧的业务故障问题 企业都没有及时发现，需要⽤⼾报障我们才后知后觉的排查问题。⿊匣⼦拨测监控系统项⽬的上线 就是解决了这⻓期以来的监控痛点。 ⿊盒监控 即以⽤⼾的⾝份测试服务的外部可⻅性，常⻅的 ⿊盒监控 包括 HTTP探针 、 TCP探针 等⽤于检测 站点或者服务的可访问性 ，以及 访问效率 等。⽽探针的设计需要⽀持对业务的交互 才能更有效的发现问题。所以在探针⼯具选型中选择了 Prometheus + blackbox_exporter 来实现需求。 拨测点需要在全国各地布点，在管理上难度较⼤，特别在兼顾拨测任务分发、拨测监控数据回收统 ⼀展⽰、告警聚合收敛的同时，还要考虑安全和应对审计等问题。架构的设计上需要严格控制 PULL和PUSH的数据流，还要和现有的采集监控系统独⽴出来。所以引⼊了Mosn做⽹格管理来降 低管理成本。 该系统的数据展⽰上默认只能⽤时序图和表格来展⽰现状，⼀个很直⽩的地域图更能说明问题。为 了做地域图的展⽰，还引进了 geohash + OpenStreetMap 来解决。 需求与功能 第一期的建设只是基本要求，但是需满足以下条件以达成业务基本需求：
⽀持对公司前端服务的证书链，DNS耗时，TLS耗时，⾸次建⽴建⽴耗时，加载完成耗时等监控 ⽀持ICMP拨测，可对⽣产业务系统的跨域内外⽹的⽹络质量监控，特别是跨域专线质量的监 控。 ⽀持DNS，TLS tcp，SMTP协议等交互监控。均⽀持在CDN服务场景，Proxy服务基础场景，邮 箱系统的使⽤场景。 同时，因为项目的0-1阶段基本都很难得到企业的深度投入，在第一期的建设也只能依赖开源项目搭建，后续逐步投入组件二开的研发资源以实现能力扩展。
架构简要 首先，定义每个拨测点为边缘孤岛，这里的边缘孤岛是因为它部署的地理位置远离企业系统的机房，分别在世界各地购买一些最便宜的虚拟机资源来部署服务，且代表当地发起拨测的请求。 利⽤了 geohash + OpenStreetMap 在告警和图展⽰中凸显了地域质量数据。 每个孤岛拨测节点需要具备基础⾃治能⼒，包括 ⾃⾝状态监控 ， 拨测任务的发起 ， ⾃⾝告警策。以下是拨测节点的内部结构，该结构在cpu为0.5core，内存为512M就足够运行，后期还可以通过二开组件的方式进一步整合资源的利用。 效果展示 拨测全局概览视图 拨测资源使用情况 告警展示   </content></entry><entry><title>监控系统企业架构演进史-跨地域混合云</title><url>/posts/opentelemetry/prometheus-evolution-history-two/</url><categories/><tags/><content type="html">  前情概述： 在《监控系统企业架构演进史-初入Prometheus》中，监控系统已经从单体架构升级到单IDC分布式架构了。 前一篇文章的内容是适用于虚拟机部署和容器部署的。Prometheus是云原生时代的产物，一般和Kubernetes配套使用，但是Prometheus本身也能在非Kubernetes取替传统监控如Zabbix使用的。 在该篇文章中，开始以Kubernetes的部署来升级整个监控系统架构，使之在跨地域混合云的业务场景中更具灵活性。
架构设计 跨地域的三层结构设计 设计三层区域结构，同时规范区域命名标签化来实现快速辨识服务的地域详细信息。 在第三层中的Cluster和VPC是同级，分别代表集群内或者某网段的隔离服务。
前端查询入口逻辑架构 用Thanos Query实现前期的层级架构 利用Thanos内的GRPC通讯协议和聚合查询能力来实现递级数据汇聚到最上层Thanos Query组件，再聚合计算时间线结果集前端展示。
引入Thanos Query Frontend完成统一前端查询入口 Thanos Query Frontend组件有以下配置能力优化查询，需根据实际情况调整：
时间线的纵向切割查询 比如查15天的数据，由于样本量的数据庞大，会在原始数据读取到内存时导致OOM问题。通过纵向切割比如把15天的聚合查询逻辑拆分成每6小时的聚合查询。 Thanos Query组件就会得到4 * 15个并发查询去完成样本查询并聚合成不同时间段的结果集再拼接展示，且每完成一个子查询聚合均及时释放内存高效优化了资源利用率。
查询结果集缓存 通过对查询语句和时间周期的HASH KEY缓存结果集到内存或者Redis以重复利用，减轻上游压力。
利用Kubernetes赋予更具弹性的冗余能力 自研架构组件 在基于原生开源项目的基础架构下，已基本实现对跨地域混合云的能力。但是要做到企业日常管理还远远不够，需要完善管理架构和前台能力才称得上企业服务。
基础设计逻辑 为了让整个架构具备灵活性和通用性，分别设计了几个组件：
Self-research service discovery 用于对接第三方系统，比如CMDB，CICD等收集业务系统和资产信息，并计算各个业务系统和基建关联关系，通过地域信息来调度资源信息同步给P-sidcar组件。 P-sidcar用于在边缘管理Prometheus，从 Self-research service discovery得到就近采集器的信息，以http_sd方式给Prometheus发现exporter采集的同时实现精细化label注入。 msg route agent 用于对接飞书、钉钉等通讯服务，同时从Conf/Rule Sync同步告警的责任人以实现高效的最后一公里定向信息推送。 A-sidcar 用于对Alertmanger集群的配置管理，并准实时同步抑制策略来对告警实现更精确的管理。 Conf/Rule Sync对接各个边缘组件。准实时同步状态信息和后台管理策略。 进阶扩展 底座设计尽量精而简，又不能失去灵活性。在此之上通过自研前台服务、中间件和边缘组件逐步丰富企业能力。
服务发现组件主打和各种三方系统对接，不限于CMDB/CICD系统，还可以对接工单系统或作业系统。 告警组件逐步升级为统一告警系统平台，和服务发现组件联动实现更高级的动态调度告警能力。 配置同步组件和Grafana逐步融合成前台系统，集管理和展示一体。 整个系统的用户侧切面逻辑如下图 到这个阶段，平台已经具备一定的复杂性了，但是对用户而言需要简化他们的理解。
统一告警系统 基本上监控平台发展到一定阶段，告警风暴问题必然会开始困扰企业内部各个技术支撑部门。告警收敛治理就会优先提上日程。 这个时候，告警的组件就可以从一开始的只是告警定向推送能力逐步丰富周边能力了。
下期期待：《数据处理-高维度的思考》   </content></entry><entry><title>监控系统企业架构演进史-初入Prometheus</title><url>/posts/opentelemetry/prometheus-evolution-history-one/</url><categories/><tags/><content type="html"><![CDATA[  Prometheus是一个开源的监控与时间序列数据库系统,在近年来得到了越来越广泛的应用。 官方的架构图如图所示： 本系列文章会以Prometheus的在一个企业里的部署架构演进过程中逐步理解和深入各种组件和概念。 先通过下图简单了解这个演进发展史 单节点架构 刚开始接触Prometheus监控体系，只需要在服务端部署Prometheus的二进制文件，用最基础的文件服务发现配置file_sd_config来实现对主机基础监控node_exporter进行拉取指标采集即可。 再通过Grafana的datasource配置Prometheus的url地址即可开始配置查看监控数据。
指标数据采集 Prometheus的数据模型主要由Metric、Label和 Sample组成。
Metric: 表示一个时序指标,对应于一个监控指标名称。如cpu_usage、free_memory等。 Metric仅包含时序数据名称,没有预定义的结构或类型。这使Prometheus具有很高的灵活性。 一个Prometheus实例可以包含任意数量的Metric。 Label: 用来描述和区分相同Metric的数据。类似于其他时序数据库的Tag。 Label通常表示数据的维度或属性,如instance、job、region等。 每个样本数据都必须包含相同的Label集。Label用于快速查询和聚合特定维度的数据。 Label的值可以是字符串、布尔值或整数。支持在Label上过滤和分组数据。 Sample: 表示一条时序数据,包含Timestamp、Value和Label集。 Timestamp表示时序数据的时间戳,精度为毫秒。它用于排序和查询给定时间范围的数据。 Value表示时序指标的值,可以是浮点数、整数或字符串。 Label集用于标识该Sample数据的属性与维度。相同Label的Sample表示同一指标的不同记录。 一个Prometheus Sample包含:
1 2 3 4 Metric - 时序指标名称 Timestamp - 时间戳,毫秒精度 Value - 指标数值 Label - 数据属性集 例如:
1 2 3 4 5 6 7 8 9 10 11 ################################################### Metric: cpu_usage Timestamp: 1577836800000 Value: 0.6 Label: instance=&#34;web01&#34;, job=&#34;webapp&#34; ################################################### Metric: free_memory Timestamp: 1577836800000 Value: 20*1024*1024 Label: instance=&#34;web01&#34;, job=&#34;webapp&#34; ################################################### 如下所示是采集到的数据结构样例
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # HELP thanos_grpc_req_panics_recovered_total Total number of gRPC requests recovered from internal panic. # TYPE thanos_grpc_req_panics_recovered_total counter thanos_grpc_req_panics_recovered_total 0 # HELP thanos_objstore_bucket_last_successful_upload_time Second timestamp of the last successful upload to the bucket. # TYPE thanos_objstore_bucket_last_successful_upload_time gauge thanos_objstore_bucket_last_successful_upload_time{bucket=&#34;thanos&#34;} 1.591146025002795e+09 # HELP thanos_objstore_bucket_operation_duration_seconds Duration of successful operations against the bucket # TYPE thanos_objstore_bucket_operation_duration_seconds histogram thanos_objstore_bucket_operation_duration_seconds_bucket{bucket=&#34;thanos&#34;,operation=&#34;delete&#34;,le=&#34;0.001&#34;} 0 thanos_objstore_bucket_operation_duration_seconds_bucket{bucket=&#34;thanos&#34;,operation=&#34;delete&#34;,le=&#34;0.01&#34;} 0 thanos_objstore_bucket_operation_duration_seconds_bucket{bucket=&#34;thanos&#34;,operation=&#34;delete&#34;,le=&#34;0.1&#34;} 0 thanos_objstore_bucket_operation_duration_seconds_bucket{bucket=&#34;thanos&#34;,operation=&#34;delete&#34;,le=&#34;0.3&#34;} 0 thanos_objstore_bucket_operation_duration_seconds_bucket{bucket=&#34;thanos&#34;,operation=&#34;delete&#34;,le=&#34;0.6&#34;} 0 thanos_objstore_bucket_operation_duration_seconds_bucket{bucket=&#34;thanos&#34;,operation=&#34;delete&#34;,le=&#34;1&#34;} 0 thanos_objstore_bucket_operation_duration_seconds_bucket{bucket=&#34;thanos&#34;,operation=&#34;delete&#34;,le=&#34;3&#34;} 0 thanos_objstore_bucket_operation_duration_seconds_bucket{bucket=&#34;thanos&#34;,operation=&#34;delete&#34;,le=&#34;6&#34;} 0 thanos_objstore_bucket_operation_duration_seconds_bucket{bucket=&#34;thanos&#34;,operation=&#34;delete&#34;,le=&#34;9&#34;} 0 thanos_objstore_bucket_operation_duration_seconds_bucket{bucket=&#34;thanos&#34;,operation=&#34;delete&#34;,le=&#34;20&#34;} 0 thanos_objstore_bucket_operation_duration_seconds_bucket{bucket=&#34;thanos&#34;,operation=&#34;delete&#34;,le=&#34;30&#34;} 0 thanos_objstore_bucket_operation_duration_seconds_bucket{bucket=&#34;thanos&#34;,operation=&#34;delete&#34;,le=&#34;60&#34;} 0 thanos_objstore_bucket_operation_duration_seconds_bucket{bucket=&#34;thanos&#34;,operation=&#34;delete&#34;,le=&#34;90&#34;} 0 thanos_objstore_bucket_operation_duration_seconds_bucket{bucket=&#34;thanos&#34;,operation=&#34;delete&#34;,le=&#34;120&#34;} 0 thanos_objstore_bucket_operation_duration_seconds_bucket{bucket=&#34;thanos&#34;,operation=&#34;delete&#34;,le=&#34;+Inf&#34;} 0 thanos_objstore_bucket_operation_duration_seconds_sum{bucket=&#34;thanos&#34;,operation=&#34;delete&#34;} 0 thanos_objstore_bucket_operation_duration_seconds_count{bucket=&#34;thanos&#34;,operation=&#34;delete&#34;} 0 Prometheus中定义了四种主要的指标类型:
Gauge(仪表盘) 适用于可任意变化的指标,如温度,pressure。 Counter(计数器) 只能单调递增的指标,适合记录如请求数,任务完成数,错误数等。 Histogram(直方图) 一般用来记录请求持续时间,响应大小等指标。它通过配置桶来记录Value分布情况。可以用来计算分位值,平均值等。 Summary 和Histogram类似,直接存储了分位值,可以更方便的计算分位值。 这四种指标类型可以表示不同类型的指标:
Gauge:瞬时值 Counter:计数总量 Histogram/Summary:统计分布 根据需要的监控指标类型选择合适的类型。Prometheus在抓取和存储样本时,会根据类型做不同的处理。我们看一下以下案例。
告警配置 当需要告警的时候，就要部署Alertmanager组件，并且开始在Prometheus配置Alertmanager的信息，告警规则需要在Prometheus配置以进行周期性计算，把达到阈值的告警信息发送给Alertmanager组件来做处理。
关于Prometheus的告警机制,以及它和Alertmanager的关系,以下简要说明:
Prometheus告警规则 Prometheus服务器中定义了告警规则(rules),它根据PromQL指定的表达式判断是否要生成告警。一旦表达式输出结果为true,则会创建一个告警事件。 Prometheus处理告警 Prometheus会记录这些告警事件,并在其状态页面上展示告警信息。Prometheus还可以通过Webhook将告警信息发送到外部系统。 Alertmanager概述 Alertmanager是一个独立的告警管理组件。它支持告警去重、分组、路由、发送等功能。Prometheus服务器生成的告警会发送给Alertmanager。 Alertmanager处理告警 Alertmanager收到告警后,可以按照定义的分组方式对其进行分组,再按照路由规则发送到对应接收方,比如邮箱、Slack等。它也负责告警的去重。 Prometheus和Alertmanager集成 在Prometheus中配置Alertmanager的URL地址,这样Prometheus生成的告警可以自动发送到Alertmanager。二者集成后,可以构成动态的告警管理机制。 综上,Prometheus负责告警检测与生成,Alertmanager专注于告警的后续分发、处理与告知流程。二者的集成可以完整实现从监控到告警的全链路。
这里开始我们要理解Prometheus的告警在时序上的状态 1、inactive：没有触发阈值 2、pending：已触发阈值但未满足告警持续时间 3、firing：已触发阈值且满足告警持续时间
用一个简单的例子来理解一下，以下配置一个mysql的告警，该指标的采集周期是5s一个样本点，配置了规则策略是每10s计算一次，当运行时小于30s则触发告警状态。
1 2 3 4 5 6 7 8 9 10 groups: - name: example rules: - alert: mysql_uptime expr: mysql:server_status:uptime &lt; 30 for: 10s labels: level: &#34;CRITICAL&#34; annotations: detail: 数据库运行时间 如上图所示
收集到的mysql_uptime&gt;=30,告警状态为inactive 收集到的mysql_uptime&lt;30,且持续时间小于10s，告警状态为pending 收集到的mysql_uptime&lt;30,且持续时间大于10s，告警状态为firing ⚠ 注意：配置中的for语法就是用来设置告警持续时间的；如果配置中不设置for或者设置为0，那么pending状态会被直接跳过。
告警内部逻辑 其内部机制可以总结为以下几个步骤:
告警的接收 Alertmanager从Prometheus等地方接收到告警后,会根据配置将告警组合成分组。 告警的分组 同类或者相关的告警会聚合到一起,形成一个告警分组,这通过配置文件中的分组规则来定义。 告警的去重 对于重复的告警,Alertmanager将进行去重,防止重复发送。 告警的路由 根据告警的匹配规则,确定该告警分组的发送路径,可能是通过邮件、Slack或者Webhook发送。 沉默和抑制 根据配置直接沉默或者在告警阶段抑制某些告警信息的发送。 告警的发送 最后Alertmanager将处理后的告警通过邮件、短信、电话等方式发送给接收人。 联邦部署 当达到一定规模，我们需要多个Prometheus帮忙分担采集和计算压力，可以尝试用联邦部署的方式来扩展架构。
⚠ 注意：个人不建议这种联邦架构，主要原因是管理成本较高，且该架构对后期的自动化二次开发不太友好。
分布式架构雏型 随着业务的扩展，监控系统也随之扩大，无论从架构管理上还是稳定性考虑都要从单体架构升级到集群架构，业界有多种方案选择：
Grafana社区的Cortex方案 Thanos社区方案 这里选择了Thanos社区的分布式方案，同时在服务发现能力上引入HashiCorp的Consul来取替文件配置服务发现的能力.
数据处理逻辑架构 通过引入Consul管理需被监控采集的exporter采集器信息，这样运维就可以通过脚本开发定时从CMDB/CICD系统同步基建和业务组件等可被采集的信息到该架构实现动态发现采集能力。 另外通过Thanos Sidecar组件同步TSDB BLOCK到对象存储备份。
数据查询逻辑架构 前端查询用Thanos Query组件来实现整个分布式集群的统一入口查询能力，Thanos Query组件自身具备数据去重和联合查询。 历史数据可以通过Thanos Compact组件长周期数据聚合和降分辨率重聚合来优化底层TSDB BLOCK 。 对象存储的数据通过Thanos Store暴露API接口查询以减轻Prometheus的计算压力。
  ]]></content></entry><entry><title>About me</title><url>/about.html</url><categories/><tags/><content type="html">  个人简介 (Self Introduction) :
I am a engineer with a rich work experience in IT field. I have extensive experience in operations, development and cloud native technologies. I have a passion for observable technologies and cloud native technologies. I have worked on shell scripts, VBA tools, Python, Lua, Golang, C and Rust. I also have experience in embedded development with Arduino and MicroPython.
我是一名经验丰富的IT技术工程师，拥有从运维到开发的丰富职业路径。我对可观测性技术充满热情，并对云原生技术有着深入的了解和实践经验。我的技术旅程始于Shell脚本，随后扩展到VBA工具开发，进而掌握了Python、Lua，并深入研究了Golang和Rust编程语言。此外，我还具备嵌入式开发的能力，包括Arduino和MicroPython等。
专业技能 (Skills) :
编程语言 (Languages)： I have extensive experience in shell scripts, VBA tools, Python, Lua, Golang, C and Rust.
精通 Shell、VBA、Python、Lua、Golang、C和Rust。
嵌入式开发 (Embedded Development)： I have experience in embedded development with Arduino and MicroPython.
掌握简单的对Esp32、STM32和RP2040等MCU的Arduino和MicroPython开发，具备嵌入式系统的开发经验。
云原生技术 (Cloud Native Technologies)： I have extensive experience in cloud native technologies such …  </content></entry><entry><title>Linode的BBR简单测试</title><url>/posts/old/linode-bbr-test/</url><categories><category>Tcp</category></categories><tags><tag>Tcp</tag></tags><content type="html">  概述: TCP BBR 致力于解决两个问题： 在有一定丢包率的网络链路上充分利用带宽。非常适合高延迟、高带宽的网络链路。 降低网络链路上的 buffer 占用率，从而降低延迟。非常适合慢速接入网络的用户。 测试目的: 这次的测试主要是针对丢包率.更有说服力的测试请参考 Lawrence Brakmo的BBR Report . BBR的另一面 测试准备： ADDR01：aaa.aaa.aaa.aaa 1 2 $ uname -r 4.8.6-x86_64-linode78 ADDR02：bbb.bbb.bbb.bbb 1 2 # uname -r 4.8.6-x86_64-linode78 测试方式： 模拟丢包1%-30%的场景，分别测试不同内核开启BBR先后的情况。 用到的tc指令： 1 2 3 4 5 6 7 8 # 清理tc规则： tc qdisc del root dev eth0 # 模拟1%丢包： tc qdisc add dev eth0 root netem loss 1% # 模拟10%丢包： tc qdisc add dev eth0 root netem loss 10% # 模拟30%丢包： tc qdisc add dev eth0 root netem loss 30% 测试从从ADDR02传数据到ADDR01,ADDR01的内核不变,ADDR02在每次测试都会调整内核重启。 测试过程： 步骤略,test.gz约160MB,过程大致如下: 没有启用BBR的情况，从ADDR02传数据到ADDR01： 1 2 3 4 5 6 $ rsync -ave &amp;amp;#34;ssh -l mickey&amp;amp;#34; --progress test.gz mickey@bbb.bbb.bbb.bbb:/home/mickey/test.gz sending incremental file list test.gz 166042909 100% 3.27MB/s 0:00:48 (xfer#1, to-check=0/1) sent 166063274 bytes received 31 bytes 3288382.28 bytes/sec total size is 166042909 speedup is 1.00 测试数据比对: …  </content></entry><entry><title>树莓派 RaspberryPi docker集群</title><url>/posts/old/rasp_pi_docker/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag><tag>Arm</tag></tags><content type="html"><![CDATA[  概述： 参考 Hypriot 的博客，我买了1块Rasp2代板和2块Rasp3代板。
其中2代默认安装了 Hypriot 的系统。3代板如果您有兴趣可以自己参考 《Building a 64bit Docker OS for the Raspberry Pi 3》 这篇文章编译一套64bit的系统。也可以直接下载作者的 已编译好镜像地址 中压缩包。
网络的问题： 日常的升级或者包安装之类的情况，都会遇到墙的问题。为了避免经常为墙而烦恼的情况，有必要给控制网络出口的路由做些调整。参考 《Shadowsocks + ChnRoute 实现 OpenWRT / LEDE 路由器自动翻墙》 解决墙的烦恼，因为这个不是这篇文的重点，具体细节略。
给每个arm板子在路由上赋予一个静态IP地址。
系统： OS细节： 个人习惯调整一下环境，如zsh,vim等，可以考虑弄个ansible-playbook或者shell脚本来简化一下。 1 2 3 4 5 6 7 # 调整默认文本工具为vim $ update-alternatives --config editor $ dpkg-reconfigure locales # 新建自己的账号并加入到docker组 $ usermod a -G docker xxx # 这步对集群很重要，修改设备的名字，否则后期加入集群会报错 $ sed -i &amp;#34;s/black-pearl/node01-pearl/&amp;#34; /boot/device-init.yaml /etc/hostname Kubernetes(本来我想用这个来管理的，但是我的pi2的docker是最新ce版本，kubeadmin提示不支持。) 参考 《Setup Kubernetes on a Raspberry Pi Cluster easily the official way!》 添加源：
1 2 $ curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - $ echo &amp;#34;deb http://apt.kubernetes.io/ kubernetes-xenial main&amp;#34; &amp;gt; …  ]]></content></entry><entry><title>ARM的点点滴滴记录</title><url>/posts/old/arm-board-note/</url><categories><category>Arm</category></categories><tags><tag>Arm</tag><tag>Linux</tag></tags><content type="html"><![CDATA[  Raspberry Pi 我用树莓派搭建docker集群环境，参考 Hypriot 的博客
CubieBoard 安装docker
选择Hypriot(截止到2017年3月版本是docker 1.11.1)
Install dependencies 1 $ apt-get install -y apt-transport-https Add respository key 1 $ wget -q https://packagecloud.io/gpg.key -O - | sudo apt-key add - Add repository 1 2 $ echo &#39;deb https://packagecloud.io/Hypriot/Schatzkiste/debian/ jessie main&#39; | sudo tee /etc/apt/sources.list.d/hypriot.list $ apt-get update Install Hypriot 1 2 $ apt-get install -y docker-hypriot $ systemctl enable docker 选择Dockerproject (随官方更新，截止2017年3月，版本17.03-ce)
Install dependencies 1 2 $ sudo apt-get update $ sudo apt-get install apt-transport-https ca-certificates Add repository 1 $ sudo apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D 用下面的命令将 APT 源添加到 source.list（将其中的 替换为下表“表一：dockerproject 对应表”的值）：
1 $ echo &#34;&lt;REPO&gt;&#34; | sudo tee /etc/apt/sources.list.d/docker.list Install Docker-Engine 1 2 $ apt-get update $ apt-get install -y docker-engine Cubietruck (系统：armbian) 问题与记录
外置硬盘挂死的原因及处理： 参考： Arch hdparm Values 1-127 permit spin-down, 128-254 do not and 255 disables advanced power management altogether (if the drive supports it).
Values 1 to 240 are in 5 second steps, values 241 to 251 are steps of 30 minutes,
see the table below.
解决方法：
1 # hdparm -B 127 /dev/sdx 被墙 利用pogoplug的shadowsocks做的ss5代理，用tsocks工具更新软件。
docker构建gogs: 利用PogoPlug在官方GIT库的Dockerfile和build.sh增加代理来完成部署
1 2 export http_proxy=http://192.168.208.88:8118 export https_proxy=http://192.168.208.88:8118 把Dockerfile参考如下修改:
1 2 3 4 5 6 RUN export http_proxy=http://192.168.208.88:8118 \ &amp;&amp; export https_proxy=http://192.168.208.88:8118 \ &amp;&amp; apk --no-cache --no-progress add curl \ &amp;&amp; curl -x 192.168.208.88:8118 -L https://github.com/tianon/gosu/releases/download/1.9/gosu-armhf -o /usr/sbin/gosu \ &amp;&amp; chmod +x /usr/sbin/gosu \ &amp;&amp; apk --no-cache --no-progress add ca-certificates bash git linux-pam s6 openssh socat tzdata PogoPlug 破狗 安装openwrt，部署shadowsocks提供ss5代理服务
打开Luci，定位到“系统”-“软件包”-“配置”选项卡，然后在设置中现将下面一行注释掉，如下： 1 #option check_signature 1 接着在末尾添加软件源： 1 2 src/gz openwrt_dist http://openwrt-dist.sourceforge.net/packages/OpenWrt/base/oxnas src/gz openwrt_dist_luci http://openwrt-dist.sourceforge.net/packages/OpenWrt/luci 更新源并安装shadowsocks 提供nfs服务
Orange Pi Orange Pi Zero (系统：armbian)问题与记录：
结合OrangePiNas板子使用. Orange Pi One (系统：dietpi)问题与记录：
默认en_GB字符，会经常报错，更改为zh_CN Nano Pi Nano Pi Neo (系统：armbian)问题与记录： Nano Pi M3 (系统：kali linux)问题与记录： Kali Linux有提供官方镜像下载: Kali Linux ARM Images 下载地址 扩容SD卡:
查看第二分区的起始地址, 后面需要 1 cat /sys/block/mmcblk0/mmcblk0p2/start 启用 fdisk 磁盘管理工具 1 fdisk /dev/mmcblk0 删除分区 1 Command (m for help): d 删除第二分区 1 Partition number (1,2, default 2): 2 创建一个新分区 1 Command (m for help): n 创建主分区 1 2 3 4 Partition type p primary (1 primary, 0 extended, 3 free) e extended (container for logical partitions) Select (default p): p 选择分区 2 1 Partition number (2-4, default 2): 2 输入第二分区起始扇区 1 First sector (125001-31116287, default 126976): 125001 输入最后一个结束扇区, 直接回车代表剩余所有
将上面的操作写入分区表
1 Command (m for help): w 重启后继续执行如下命令，否则容量还是以前的,重新分配分区大小 1 resize2fs /dev/mmcblk0p2 到此扩容完成。使用 df -lh 查看容量已扩至 SD 卡实际所有可用物理容量。 附表： 表一：dockerproject 对应表
操作系统版本 REPO Precise 12.04 (LTS) deb https://apt.dockerproject.org/repo ubuntu-precise main Trusty 14.04 (LTS) deb https://apt.dockerproject.org/repo ubuntu-trusty main Xenial 16.04 (LTS) deb https://apt.dockerproject.org/repo ubuntu-xenial main Debian 7 Wheezy deb https://apt.dockerproject.org/repo debian-wheezy main Debian 8 Jessie deb https://apt.dockerproject.org/repo debian-jessie main Debian Stretch/Sid deb https://apt.dockerproject.org/repo debian-stretch main   ]]></content></entry><entry><title>GitHub博客的搭建</title><url>/posts/old/blog-mickeyzzc-github/</url><categories><category>GitHub</category></categories><tags><tag>GitHub</tag></tags><content type="html"><![CDATA[  2023年的博客从hexo切换到hugo 工具选用了 hugo 主题选择了 Hugo.NexT CDN选择了 CloudFlare 迁移过程 搭建hugo新环境 1 2 3 4 5 6 7 hugo new site mickeyzzcblog cd mickeyzzcblog git init git submodule add https://github.com/hugo-next/hugo-theme-next.git themes/hugo-theme-next cp themes/hugo-theme-next/exampleSite/config.yaml . vim config.yaml hugo server 构建github ci的workflows 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 name: deploy on: push: workflow_dispatch: schedule: # Runs everyday at 8:00 AM - cron: &amp;#34;0 0 * * *&amp;#34; jobs: build: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v2 with: submodules: true fetch-depth: 0 - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: &amp;#34;latest&amp;#34; extended: true - name: Build Web run: hugo - name: Deploy Web uses: peaceiris/actions-gh-pages@v3 with: PERSONAL_TOKEN: ${{ secrets.PERSONAL_TOKEN }} EXTERNAL_REPOSITORY: mickeyzzc/mickeyzzc.github.io PUBLISH_BRANCH: main PUBLISH_DIR: …  ]]></content></entry><entry><title>监控采集点点记录</title><url>/posts/opentelemetry/monitor-experience/</url><categories><category>Monitor</category></categories><tags><tag>Mysql</tag><tag>Tcp</tag><tag>Linux</tag></tags><content type="html"><![CDATA[  MYSQL的监控 MySQL权限经验原则 权限控制主要是出于安全因素，因此需要遵循一下几个经验原则：
只授予能满足需要的最小权限，防止用户干坏事。比如用户只是需要查询，那就只给select权限就可以了，不要给用户赋予update、insert或者delete权限。 创建用户的时候限制用户的登录主机，一般是限制成指定IP或者内网IP段。 初始化数据库的时候删除没有密码的用户。安装完数据库的时候会自动创建一些用户，这些用户默认没有密码。 为每个用户设置满足密码复杂度的密码。 定期清理不需要的用户。回收权限或者删除用户。 eg:
针对MYSQL的监控需要开监控账号，针对本地监控和远程监控的分别授权；
1 2 GRANT USAGE,PROCESS,REPLICATION CLIENT,REPLICATION SLAVE ON *.* TO &amp;#39;monitor&amp;#39;@&amp;#39;10.12.%&amp;#39; IDENTIFIED BY &amp;#39;xxx&amp;#39;; GRANT USAGE,SUPER,PROCESS,REPLICATION CLIENT,REPLICATION SLAVE ON *.* TO &amp;#39;monitor&amp;#39;@&amp;#39;localhost&amp;#39; IDENTIFIED BY &amp;#39;xxx&amp;#39;; 监控手段 show global status; 查看全局状态
show global variables; 查看全局变量设置
mysqladmin MySQL管理工具
show master status; 查看Master状态
show slave status; 查看Slave状态
show binary logs; 查看二进制日志文件
show engine innodb status\G 查看InnoDB存储引擎状态
show engine myisam status\G 查看MyISAM存储引擎状态
还有通过查看information_schema 这个数据库获取InnoDB存储引擎相关信息
权限表 权限 权限级别 权限说明 CREATE 数据库、表或索引 创建数据库、表或索引权限 DROP 数据库或表 删除数据库或表权限 GRANT OPTION 数据库、表或保存的程序 赋予权限选项 REFERENCES 数据库或表 …  ]]></content></entry><entry><title>跨城区局域网的搭建（基于Docker）</title><url>/posts/old/mi-docker-net/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag><tag>VPN</tag></tags><content type="html"><![CDATA[  概述： 管理复杂网络内的系统,有时候需要突破网络限制.有比较多的方案,比如ss5,Shadowsocks,vpn等. 这里提供一种方案是利用 docker-openvpn 实施多重复杂网络内的主机互联,实现利用nginx反向代理各类服务.
概念图： 具体流程： 购买云服务器部署docker 建议购买支持systemctl的Linux系统,比较好管理,并部署docker:
外挂存储格式化为xfs分区; 1 2 # mkfs.xfs /dev/vdb5 # echo &amp;#34;/dev/vdb5 /mnt/data xfs defaults 1 1&amp;#34; |tee -a /etc/fstab 调整docker的目录,两种方法; 挂载/var/lib/docker目录: 1 2 3 4 5 6 # systemctl stop docker # mkdir -p /mnt/data/docker # rsync -aXS /var/lib/docker/. /mnt/data/docker/ # echo &amp;#34;/mnt/data/docker /var/lib/docker none bind 0 0&amp;#34;|tee -a /etc/fstab # mount -a # systemctl start docker 指定具体目录: 在/etc/systemd/system/multi-user.target.wants/docker.service里面修改如下: 1 ExecStart=/usr/bin/dockerd --storage-driver=overlay2 -g /mnt/hhd/docker 安装docker-openvpn服务: docker-openvpn Pick a name for the $OVPN_DATA data volume container, it will be created automatically. 1 # OVPN_DATA=&amp;#34;ovpn-data&amp;#34; Initialize the $OVPN_DATA container that will hold the configuration files and certificates 1 2 3 4 5 6 # docker volume …  ]]></content></entry><entry><title>Tumx + Git + OhMyZsh + VIM</title><url>/posts/old/zsh-tmux-vim-git/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>Tumx</tag><tag>Zsh</tag></tags><content type="html"><![CDATA[  Ubuntu下的环境： 要求： tmux &amp;gt;= 2.1 vim &amp;gt;= 7.3 zsh (oh-my-zsh) git 部署环境： TMUX(使用 gpakosz 的配置)： 部署方式： 1 2 3 4 5 $ cd ~ $ git clone https://github.com/gpakosz/.tmux.git $ ln -s -f .tmux/.tmux.conf $ cp .tmux/.tmux.conf.local . $ sudo apt-get install xclip ## Ubuntu下安装xclip来支持跨文件复制粘贴 修改“.tmux.conf” 把以下地方修改： 1 bind -t vi-copy y copy-selection 改为
1 bind -t vi-copy y copy-pipe &amp;#34;xclip -sel clip -i&amp;#34; 如果tmux &amp;lt;1.8 请修改如下：
1 2 3 # copy &amp;amp; paste between tmux and x clipboard bind C-p run-shell &amp;#34;tmux set-buffer \&amp;#34;$(xclip -o)\&amp;#34;; tmux paste-buffer&amp;#34; bind C-y run-shell &amp;#34;tmux show-buffer | xclip -sel clip -i&amp;#34; 修改“.tmux.conf.local”把以下地方注释去掉：
1 2 # set -g status-keys vi # set -g mode-keys vi GIT： 日常都会用到几个git库，有包含同事的和自己的。管理起来都比较麻烦，但是利用到git子模块会比较方便。
1 2 3 4 5 6 7 $ mkdir xxxx $ git init $ git remote add origin ssh://git@git.xxx.net/mickey/xxxx.git $ git submodule add ssh://git@git.xxx.net/mickey/tttt.git xxxx $ git add -A $ git commit -m &amp;#34;add submodule tttt&amp;#34; $ git …  ]]></content></entry></search>